#!/bin/sh

# paraphrase-multilingual-mpnet-base-v2 æ¨¡å‹ä¸‹è½½è„šæœ¬ v2.7.0
# å¤šè¯­è¨€æ¨¡å‹ï¼ˆåŒ…å«ä¸­æ–‡ï¼‰ï¼Œé¡¹ç›®ä¸»è¦ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹
# å¯å•ç‹¬æ‰§è¡Œæ­¤è„šæœ¬å®Œæˆæ¨¡å‹ä¸‹è½½

set -e

echo "=== paraphrase-multilingual-mpnet-base-v2 æ¨¡å‹ä¸‹è½½è„šæœ¬ v2.7.0 ==="
echo "ğŸ¤– æ­£åœ¨ä¸‹è½½å¤šè¯­è¨€Sentence-Transformersæ¨¡å‹..."
echo "ğŸ“ æ³¨æ„: è¿™æ˜¯é¡¹ç›®ä¸»è¦ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹"
echo ""

# æ£€æŸ¥Pythonæ˜¯å¦å¯ç”¨
if ! command -v python3 >/dev/null 2>&1; then
    echo "âŒ é”™è¯¯: æœªæ‰¾åˆ°python3å‘½ä»¤"
    echo "   Ubuntuå®‰è£…å‘½ä»¤: sudo apt-get install python3"
    echo "   macOSå®‰è£…å‘½ä»¤: brew install python3"
    exit 1
fi

echo "ğŸ Pythonç‰ˆæœ¬ä¿¡æ¯:"
python3 --version
echo ""

# åŠ è½½ç½‘ç»œé…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"
NETWORK_CONFIG_ALL="$SCRIPT_DIR/.network_config.all"
NETWORK_CONFIG_PROXY="$SCRIPT_DIR/.network_config"
NETWORK_CONFIG_MIRROR="$SCRIPT_DIR/.network_config.mirror"
NETWORK_CONFIG_ENV="$SCRIPT_DIR/.network_config.env"

echo "ğŸŒ æ£€æŸ¥ç½‘ç»œé…ç½®..."
if [ -f "$NETWORK_CONFIG_ALL" ]; then
    echo "âœ… åŠ è½½å®Œæ•´ç½‘ç»œé…ç½®"
    . "$NETWORK_CONFIG_ALL"
else
    # åˆ†åˆ«åŠ è½½å„ä¸ªé…ç½®æ–‡ä»¶
    [ -f "$NETWORK_CONFIG_PROXY" ] && . "$NETWORK_CONFIG_PROXY" && echo "âœ… åŠ è½½ä»£ç†é…ç½®"
    [ -f "$NETWORK_CONFIG_MIRROR" ] && . "$NETWORK_CONFIG_MIRROR" && echo "âœ… åŠ è½½é•œåƒæºé…ç½®"
    [ -f "$NETWORK_CONFIG_ENV" ] && . "$NETWORK_CONFIG_ENV" && echo "âœ… åŠ è½½ç¯å¢ƒä¼˜åŒ–é…ç½®"
fi

# æ˜¾ç¤ºå½“å‰ç½‘ç»œé…ç½®çŠ¶æ€
if [ -n "$HTTP_PROXY" ] || [ -n "$HTTPS_PROXY" ] || [ -n "$ALL_PROXY" ]; then
    echo "ğŸ”— ä»£ç†: å·²é…ç½®"
fi
if [ -n "$HF_ENDPOINT" ]; then
    echo "ğŸª é•œåƒæº: $HF_ENDPOINT"
fi
echo ""

# æ£€æŸ¥sentence-transformersæ˜¯å¦å·²å®‰è£…
echo "ğŸ” æ£€æŸ¥ä¾èµ–..."
python3 -c "
try:
    import sentence_transformers
    print('âœ… sentence-transformers å·²å®‰è£…')
except ImportError:
    print('âŒ ç¼ºå°‘ä¾èµ–: sentence-transformers')
    print('è¯·å…ˆè¿è¡Œ: pip install sentence-transformers')
    exit(1)
" 2>/dev/null

if [ $? -ne 0 ]; then
    echo ""
    echo "ğŸ’¡ æç¤º: è¯·å…ˆå®‰è£…sentence-transformers"
    echo "   pip install sentence-transformers"
    exit 1
fi

# åˆ›å»ºæ¨¡å‹ä¸‹è½½Pythonè„šæœ¬
cat > /tmp/download_paraphrase_multilingual_mpnet_base_v2.py << 'EOF'
from sentence_transformers import SentenceTransformer
import os
import sys
import time

# æ¨¡å‹ä¿¡æ¯
MODEL_NAME = "paraphrase-multilingual-mpnet-base-v2"
MODEL_DESC = "å¤šè¯­è¨€æ¨¡å‹ï¼ˆåŒ…å«ä¸­æ–‡ï¼‰"
MODEL_SIZE = "~470MB"

print(f"ğŸ¤– æ¨¡å‹: {MODEL_NAME}")
print(f"ğŸ“ æè¿°: {MODEL_DESC}")
print(f"ğŸ“¦ å¤§å°: {MODEL_SIZE}")
print("â­ ç‰¹åˆ«è¯´æ˜: è¿™æ˜¯é¡¹ç›®é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„ä¸»è¦åµŒå…¥æ¨¡å‹")
print("")

# è®¾ç½®ç¼“å­˜ç›®å½•
cache_dir = os.path.expanduser("~/.cache/sentence_transformers")
os.makedirs(cache_dir, exist_ok=True)
print(f"ğŸ“ æ¨¡å‹ç¼“å­˜ç›®å½•: {cache_dir}")
print("")

# è®¾ç½®ç¯å¢ƒå˜é‡ä»¥æ”¹å–„Ubuntuä¸‹çš„ä¸‹è½½ä½“éªŒ
os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # é¿å…tokenizersè­¦å‘Š
os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = 'false'  # ç¡®ä¿æ˜¾ç¤ºè¿›åº¦æ¡

# ä¼˜å…ˆä½¿ç”¨ç¨³å®šçš„é˜¿é‡Œäº‘é•œåƒæº
hf_endpoint = os.environ.get('HF_ENDPOINT')

# æ£€æµ‹å¹¶ä¿®å¤å¯èƒ½çš„ä¸ç¨³å®šé•œåƒæº
unstable_mirrors = [
    'https://mirrors.tuna.tsinghua.edu.cn/huggingface',
    'https://mirrors.bfsu.edu.cn/huggingface',
]

if hf_endpoint in unstable_mirrors:
    print(f"âš ï¸  æ£€æµ‹åˆ°å¯èƒ½ä¸ç¨³å®šçš„é•œåƒæº: {hf_endpoint}")
    print("ğŸ”„ è‡ªåŠ¨åˆ‡æ¢åˆ°ç¨³å®šçš„é˜¿é‡Œäº‘é•œåƒæº")
    hf_endpoint = None

if not hf_endpoint:
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    print("ğŸª ä½¿ç”¨ç¨³å®šçš„é˜¿é‡Œäº‘é•œåƒæº: https://hf-mirror.com")
    print("   è¿™æ˜¯ç»è¿‡éªŒè¯çš„ç¨³å®šé•œåƒæºï¼Œæ¨èä½¿ç”¨")
else:
    print(f"ğŸª ä½¿ç”¨é…ç½®çš„é•œåƒæº: {hf_endpoint}")

# æ¸…é™¤å¯èƒ½å†²çªçš„ç¯å¢ƒå˜é‡
if 'HUGGINGFACE_HUB_DEFAULT_ENDPOINT' in os.environ:
    if os.environ['HUGGINGFACE_HUB_DEFAULT_ENDPOINT'] in unstable_mirrors:
        print("ğŸ§¹ æ¸…é™¤ä¸ç¨³å®šçš„HUGGINGFACE_HUB_DEFAULT_ENDPOINTè®¾ç½®")
        del os.environ['HUGGINGFACE_HUB_DEFAULT_ENDPOINT']

# ç½‘ç»œä¼˜åŒ–é…ç½®
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# é…ç½®requestsä¼šè¯ä»¥æ”¯æŒé‡è¯•å’Œä»£ç†
session = requests.Session()
retry_strategy = Retry(
    total=3,
    backoff_factor=1,
    status_forcelist=[429, 500, 502, 503, 504],
)
adapter = HTTPAdapter(max_retries=retry_strategy)
session.mount("http://", adapter)
session.mount("https://", adapter)

# åº”ç”¨ä»£ç†é…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
proxies = {}
if os.environ.get('HTTP_PROXY'):
    proxies['http'] = os.environ.get('HTTP_PROXY')
if os.environ.get('HTTPS_PROXY'):
    proxies['https'] = os.environ.get('HTTPS_PROXY')
if os.environ.get('ALL_PROXY'):
    proxies['http'] = os.environ.get('ALL_PROXY')
    proxies['https'] = os.environ.get('ALL_PROXY')

if proxies:
    session.proxies.update(proxies)
    print(f"ğŸ”— ä½¿ç”¨ä»£ç†é…ç½®: {list(proxies.values())[0]}")

# ç¡®è®¤æœ€ç»ˆä½¿ç”¨çš„é•œåƒæº
final_hf_endpoint = os.environ.get('HF_ENDPOINT', 'https://hf-mirror.com')
print(f"âœ… æœ€ç»ˆä½¿ç”¨é•œåƒæº: {final_hf_endpoint}")

# è®¾ç½®huggingface_hubä½¿ç”¨é•œåƒæº
os.environ['HUGGINGFACE_HUB_DEFAULT_ENDPOINT'] = final_hf_endpoint

# é‡è¯•æœºåˆ¶ - å¯¹äºé¡¹ç›®ä¸»è¦æ¨¡å‹ï¼Œæé«˜é‡è¯•æ¬¡æ•°
MAX_RETRIES = 5  # é¡¹ç›®ä¸»è¦æ¨¡å‹ï¼Œæé«˜é‡è¯•æ¬¡æ•°
RETRY_DELAY = 10  # æ›´é•¿çš„é‡è¯•é—´éš”

for attempt in range(1, MAX_RETRIES + 1):
    try:
        print(f"ğŸ”„ å¼€å§‹ä¸‹è½½ {MODEL_NAME} æ¨¡å‹... (å°è¯• {attempt}/{MAX_RETRIES})")
        if attempt > 1:
            print(f"   ç­‰å¾… {RETRY_DELAY} ç§’åé‡è¯•... (é¡¹ç›®ä¸»è¦æ¨¡å‹ï¼Œè€å¿ƒç­‰å¾…)")
            time.sleep(RETRY_DELAY)
        
        print("   è¿™æ˜¯ä¸€ä¸ªå¤§å‹å¤šè¯­è¨€æ¨¡å‹(470MB)ï¼Œä¸‹è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´...")
        print("   è¯·ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®šï¼Œå¹¶æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´")
        print("   å¦‚æœæ²¡æœ‰è¿›åº¦æ¡æ˜¾ç¤ºï¼Œè¯´æ˜æ­£åœ¨åå°ä¸‹è½½ï¼Œè¯·ç¨å€™...")
        print("   â­ è¿™æ˜¯é¡¹ç›®çš„ä¸»è¦åµŒå…¥æ¨¡å‹ï¼Œå»ºè®®ä¼˜å…ˆä¸‹è½½")
        
        # ä¸‹è½½æ¨¡å‹
        model = SentenceTransformer(MODEL_NAME, cache_folder=cache_dir)
    
        print(f"âœ… {MODEL_NAME} ä¸‹è½½å®Œæˆ")
        
        # å¤šè¯­è¨€æµ‹è¯•
        print("ğŸ§ª è¿›è¡Œå¤šè¯­è¨€æ¨¡å‹æµ‹è¯•...")
        test_sentences = [
            "Hello, this is an English sentence.",
            "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸­æ–‡å¥å­ã€‚",
            "Bonjour, ceci est une phrase en franÃ§ais.",
            "Hola, esta es una oraciÃ³n en espaÃ±ol."
        ]
        embeddings = model.encode(test_sentences)
        print(f"   âœ“ æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºç»´åº¦: {embeddings.shape}")
        print(f"   âœ“ å‘é‡ç»´åº¦: {embeddings.shape[1]}")
        
        # è®¡ç®—ä¸­è‹±æ–‡ç›¸ä¼¼åº¦ç¤ºä¾‹
        from sentence_transformers.util import cos_sim
        english_text = "This is a test sentence"
        chinese_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å¥å­"
        
        eng_emb = model.encode([english_text])
        chi_emb = model.encode([chinese_text])
        similarity = cos_sim(eng_emb, chi_emb)
        print(f"   âœ“ ä¸­è‹±æ–‡ç›¸ä¼¼åº¦æµ‹è¯•: {similarity.item():.4f}")
        
        print("")
        print("ğŸ‰ paraphrase-multilingual-mpnet-base-v2 æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        print("")
        print("ğŸ“ æ¨¡å‹ä¿¡æ¯:")
        print(f"   - å­˜å‚¨ä½ç½®: {cache_dir}")
        print("   - ç”¨é€”: å¤šè¯­è¨€æ–‡æœ¬å‘é‡åŒ–ã€è·¨è¯­è¨€è¯­ä¹‰ç†è§£")
        print("   - é€‚ç”¨åœºæ™¯: ä¸­è‹±æ–‡æ··åˆå¤„ç†ã€å¤šè¯­è¨€åº”ç”¨")
        print("   - è¯­è¨€æ”¯æŒ: 50+ ç§è¯­è¨€ï¼ŒåŒ…æ‹¬ä¸­æ–‡ã€è‹±æ–‡")
        print("   - é¡¹ç›®çŠ¶æ€: ä¸»è¦åµŒå…¥æ¨¡å‹ (config/model.yaml)")
        
        # ä¸‹è½½æˆåŠŸï¼Œé€€å‡ºé‡è¯•å¾ªç¯
        break
        
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ {MODEL_NAME} ä¸‹è½½å¤±è´¥ (å°è¯• {attempt}/{MAX_RETRIES}): {error_msg}")
        
        if attempt < MAX_RETRIES:
            if "Connection" in error_msg or "ProtocolError" in error_msg or "timeout" in error_msg.lower():
                print("ğŸ”„ æ£€æµ‹åˆ°ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œå‡†å¤‡é‡è¯•...")
                print(f"   âš ï¸  ä¸»è¦æ¨¡å‹ä¸‹è½½å¼‚å¸¸é‡è¦ï¼Œå°†åœ¨ {RETRY_DELAY} ç§’åé‡è¯•")
                continue
            else:
                print("âŒ éç½‘ç»œé”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                break
        else:
            print("")
            print("âŒ æ‰€æœ‰é‡è¯•å‡å¤±è´¥ - ä¸»è¦æ¨¡å‹ä¸‹è½½å¼‚å¸¸ä¸¥é‡ï¼")
            print("ğŸ’¡ å¼ºçƒˆå»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
            print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œç¨³å®šæ€§")
            print("   2. æ£€æŸ¥é˜²ç«å¢™/ä»£ç†è®¾ç½®")
            print("   3. æ£€æŸ¥ç£ç›˜ç©ºé—´(è‡³å°‘éœ€è¦600MB)")
            print("   4. å°è¯•ä½¿ç”¨æ›´ç¨³å®šçš„ç½‘ç»œç¯å¢ƒ")
            print("   5. ç¨åé‡æ–°è¿è¡Œè„šæœ¬")
            print("   6. æ¨¡å‹ä¼šåœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½")
            print("")
            print("ğŸ”§ Ubuntuç‰¹å®šè§£å†³æ–¹æ¡ˆ:")
            print("   - å°è¯•: export HF_HUB_DISABLE_PROGRESS_BARS=false")
            print("   - æˆ–è€…: pip install --upgrade requests urllib3 certifi")
            print("   - æˆ–è€…: pip install --upgrade huggingface_hub")
            print("")
            print("ğŸ”§ ç½‘ç»œé—®é¢˜è§£å†³æ–¹æ¡ˆ:")
            print("   1. ä½¿ç”¨ä»£ç†: export HTTP_PROXY=http://127.0.0.1:7890")
            print("   2. åˆ‡æ¢é•œåƒæº: export HF_ENDPOINT=https://mirrors.bfsu.edu.cn/huggingface")
            print("   3. ä½¿ç”¨å®˜æ–¹æº: export HF_ENDPOINT=https://huggingface.co")
            print("   4. é‡ç½®ç¯å¢ƒ: unset HF_ENDPOINT && unset HUGGINGFACE_HUB_DEFAULT_ENDPOINT")
            print("")
            print("âš ï¸  æ³¨æ„: è¿™æ˜¯é¡¹ç›®çš„ä¸»è¦åµŒå…¥æ¨¡å‹ï¼Œå»ºè®®ä¼˜å…ˆè§£å†³æ­¤é—®é¢˜")
            sys.exit(1)
EOF

# æ‰§è¡Œä¸‹è½½
echo "ğŸš€ å¼€å§‹æ‰§è¡Œæ¨¡å‹ä¸‹è½½..."
python3 /tmp/download_paraphrase_multilingual_mpnet_base_v2.py

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm -f /tmp/download_paraphrase_multilingual_mpnet_base_v2.py

echo ""
echo "âœ… paraphrase-multilingual-mpnet-base-v2 æ¨¡å‹ä¸‹è½½è„šæœ¬æ‰§è¡Œå®Œæˆï¼"
