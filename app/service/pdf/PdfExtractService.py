"""
PDFæ–‡æ¡£ç»“æ„åŒ–å†…å®¹æå–æœåŠ¡

åŸºäºunstructuredåº“çš„PDFæ–‡æ¡£ç»“æ„åŒ–å†…å®¹æå–ç³»ç»Ÿï¼Œæ”¯æŒæå–æ–‡æœ¬ã€æ ‡é¢˜ã€è¡¨æ ¼ã€å›¾ç‰‡ç­‰å¤šç§å†…å®¹ç±»å‹ï¼Œ
å¹¶è®°å½•å…¶åæ ‡å’Œå…ƒæ•°æ®ä¿¡æ¯ã€‚ç”Ÿæˆçš„JSONæ ¼å¼é€‚ç”¨äºå‘é‡åŒ–å’Œå®ä½“å…³ç³»æå–ã€‚

åŠŸèƒ½ç‰¹ç‚¹ï¼š
1. æ”¯æŒä¸­è‹±æ–‡PDFæ–‡æ¡£å¤„ç†
2. æå–æ–‡æœ¬ã€æ ‡é¢˜ã€è¡¨æ ¼ã€å›¾ç‰‡ç­‰å¤šç§å†…å®¹ç±»å‹
3. è®°å½•å…ƒç´ åæ ‡å’Œé¡µé¢ä¿¡æ¯
4. ç”Ÿæˆç»“æ„åŒ–JSONï¼Œé€‚åˆå‘é‡åŒ–å’ŒçŸ¥è¯†å›¾è°±æ„å»º
5. ä¿æŒæ–‡æ¡£å±‚æ¬¡ç»“æ„å’Œä¸Šä¸‹æ–‡å…³ç³»

ä½¿ç”¨æ–¹æ³•ï¼š
    extractor = PdfExtractService()
    result = extractor.extract_pdf_content("/path/to/pdf/file.pdf")
"""

import os
import json
import hashlib
import yaml
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import logging
from pathlib import Path

# unstructuredåº“å¯¼å…¥
from unstructured.partition.pdf import partition_pdf
from unstructured.staging.base import dict_to_elements, elements_to_json
from unstructured.chunking.title import chunk_by_title

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class PdfExtractService:
    """PDFæ–‡æ¡£ç»“æ„åŒ–å†…å®¹æå–æœåŠ¡ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–PDFæå–æœåŠ¡"""
        self.supported_languages = ['zh', 'en']  # æ”¯æŒä¸­è‹±æ–‡
        self.element_types = {
            'Title': 'æ ‡é¢˜',
            'NarrativeText': 'æ­£æ–‡',
            'ListItem': 'åˆ—è¡¨é¡¹',
            'Table': 'è¡¨æ ¼', 
            'Image': 'å›¾ç‰‡',
            'Header': 'é¡µçœ‰',
            'Footer': 'é¡µè„š',
            'UncategorizedText': 'æœªåˆ†ç±»æ–‡æœ¬'
        }
        # åŠ è½½é…ç½®
        self.config = self._load_config()
    
    def extract_pdf_content(self, pdf_file_path: str) -> Dict[str, Any]:
        """
        PDFæ–‡æ¡£å†…å®¹æå–ä¸»å…¥å£å‡½æ•°
        
        Args:
            pdf_file_path (str): PDFæ–‡ä»¶çš„ç»å¯¹è·¯å¾„
            
        Returns:
            Dict[str, Any]: ç»“æ„åŒ–çš„JSONæ•°æ®ï¼ŒåŒ…å«æ–‡æ¡£å…ƒæ•°æ®å’Œæå–çš„å†…å®¹
            
        Raises:
            FileNotFoundError: å½“PDFæ–‡ä»¶ä¸å­˜åœ¨æ—¶
            Exception: å½“PDFå¤„ç†å¤±è´¥æ—¶
        """
        try:
            # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§
            if not os.path.exists(pdf_file_path):
                raise FileNotFoundError(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_file_path}")
                
            logger.info(f"å¼€å§‹å¤„ç†PDFæ–‡ä»¶: {pdf_file_path}")
            
            # ä½¿ç”¨unstructuredåº“è¿›è¡ŒPDFåˆ†å‰²å¤„ç†
            elements = partition_pdf(
                filename=pdf_file_path,
                strategy="fast",  # ä½¿ç”¨å¿«é€Ÿç­–ç•¥ï¼Œé¿å…ä¸‹è½½å¤§å‹æ¨¡å‹
                infer_table_structure=True,  # æ¨æ–­è¡¨æ ¼ç»“æ„
                extract_images_in_pdf=False,  # æš‚æ—¶å…³é—­å›¾ç‰‡æå–ä»¥é¿å…ç½‘ç»œé—®é¢˜
                include_page_breaks=True,  # åŒ…å«åˆ†é¡µä¿¡æ¯
                languages=self.supported_languages,  # æ”¯æŒçš„è¯­è¨€
            )
            
            # ç”Ÿæˆæ–‡æ¡£åŸºç¡€ä¿¡æ¯
            doc_metadata = self._generate_document_metadata(pdf_file_path)
            
            # å¤„ç†å’Œç»“æ„åŒ–å…ƒç´ 
            structured_elements = self._process_elements(elements)
            
            # ç”Ÿæˆç²¾ç®€çš„AIæ ¸å¿ƒJSONç»“æ„
            result = {
                "document_info": {
                    "file_hash": doc_metadata["file_hash"],
                    "file_name": doc_metadata["file_name"],
                    "total_pages": self._get_total_pages(structured_elements)
                },
                "elements": self._generate_ai_core_elements(structured_elements)
            }
            
            logger.info(f"PDFå¤„ç†å®Œæˆï¼Œæå–äº† {len(result['elements'])} ä¸ªæœ‰æ•ˆAIæ ¸å¿ƒå…ƒç´ ")
            
            # ä¿å­˜JSONæ–‡ä»¶åˆ°é…ç½®çš„ç›®å½•
            saved_path = self._save_json_result(result, pdf_file_path)
            if saved_path:
                logger.info(f"JSONæ–‡ä»¶å·²ä¿å­˜åˆ°: {saved_path}")
                result["saved_json_path"] = saved_path
            
            return result
            
        except Exception as e:
            logger.error(f"PDFå¤„ç†å¤±è´¥: {str(e)}")
            raise Exception(f"PDFæ–‡æ¡£æå–å¤±è´¥: {str(e)}")
    
    def _generate_document_metadata(self, pdf_file_path: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ–‡æ¡£å…ƒæ•°æ®ä¿¡æ¯
        
        Args:
            pdf_file_path (str): PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict[str, Any]: æ–‡æ¡£å…ƒæ•°æ®
        """
        file_path = Path(pdf_file_path)
        file_stats = file_path.stat()
        
        # ç”Ÿæˆæ–‡ä»¶å“ˆå¸Œå€¼
        with open(pdf_file_path, 'rb') as f:
            file_hash = hashlib.md5(f.read()).hexdigest()
        
        return {
            "file_name": file_path.name,
            "file_path": str(file_path.absolute()),
            "file_size": file_stats.st_size,
            "file_hash": file_hash,
            "created_time": datetime.fromtimestamp(file_stats.st_ctime).isoformat(),
            "modified_time": datetime.fromtimestamp(file_stats.st_mtime).isoformat(),
            "file_extension": file_path.suffix.lower()
        }
    
    def _generate_ai_core_elements(self, structured_elements: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ç”ŸæˆAIæ ¸å¿ƒåŠŸèƒ½æ‰€éœ€çš„ç²¾ç®€å…ƒç´ åˆ—è¡¨
        
        Args:
            structured_elements (List[Dict[str, Any]]): å®Œæ•´çš„ç»“æ„åŒ–å…ƒç´ åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: AIæ ¸å¿ƒå­—æ®µçš„ç²¾ç®€å…ƒç´ åˆ—è¡¨
        """
        ai_core_elements = []
        
        for element in structured_elements:
            # åªä¿ç•™AIæ ¸å¿ƒåŠŸèƒ½å¿…éœ€çš„å­—æ®µ
            core_element = {
                "element_id": element.get("element_id"),
                "vectorization_text": element.get("vectorization_text"),
                "text_content": element.get("text_content"),
                "page_number": element.get("page_number"),
                "coordinates": element.get("coordinates"),
                "context_info": element.get("context_info")
            }
            
            # è¿‡æ»¤æ‰Noneå€¼å’Œç©ºå­—ç¬¦ä¸²çš„å…ƒç´ 
            if core_element["text_content"] or core_element["vectorization_text"]:
                ai_core_elements.append(core_element)
        
        return ai_core_elements
    
    def _get_total_pages(self, structured_elements: List[Dict[str, Any]]) -> int:
        """
        è·å–æ–‡æ¡£æ€»é¡µæ•°
        
        Args:
            structured_elements (List[Dict[str, Any]]): ç»“æ„åŒ–å…ƒç´ åˆ—è¡¨
            
        Returns:
            int: æ–‡æ¡£æ€»é¡µæ•°
        """
        pages = set()
        for element in structured_elements:
            if element.get("page_number"):
                pages.add(element["page_number"])
        return len(pages) if pages else 0

    def _process_elements(self, elements: List) -> List[Dict[str, Any]]:
        """
        å¤„ç†å’Œç»“æ„åŒ–æå–çš„å…ƒç´ 
        
        Args:
            elements (List): unstructuredåº“æå–çš„åŸå§‹å…ƒç´ åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: ç»“æ„åŒ–çš„å…ƒç´ åˆ—è¡¨
        """
        structured_elements = []
        
        for idx, element in enumerate(elements):
            try:
                # è·å–å…ƒç´ åŸºæœ¬ä¿¡æ¯
                element_data = {
                    "element_id": f"elem_{idx:06d}",
                    "element_type": str(type(element).__name__),
                    "element_type_cn": self.element_types.get(str(type(element).__name__), "æœªçŸ¥ç±»å‹"),
                    "text_content": str(element),
                    "text_length": len(str(element)),
                }
                
                # æ·»åŠ åæ ‡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if hasattr(element, 'metadata') and element.metadata:
                    metadata = element.metadata
                    
                    # é¡µé¢ä¿¡æ¯
                    if hasattr(metadata, 'page_number'):
                        element_data["page_number"] = metadata.page_number
                    
                    # åæ ‡ä¿¡æ¯
                    if hasattr(metadata, 'coordinates') and metadata.coordinates:
                        coords = metadata.coordinates
                        element_data["coordinates"] = {
                            "points": list(coords.points) if hasattr(coords, 'points') and coords.points else None,
                            "system": str(coords.system) if hasattr(coords, 'system') and coords.system else None,
                            "layout_width": float(coords.layout_width) if hasattr(coords, 'layout_width') and coords.layout_width else None,
                            "layout_height": float(coords.layout_height) if hasattr(coords, 'layout_height') and coords.layout_height else None
                        }
                    
                    # å…¶ä»–å…ƒæ•°æ®
                    if hasattr(metadata, 'filename'):
                        element_data["source_filename"] = str(metadata.filename)
                    if hasattr(metadata, 'filetype'):
                        element_data["source_filetype"] = str(metadata.filetype)
                    if hasattr(metadata, 'languages'):
                        element_data["detected_languages"] = list(metadata.languages) if metadata.languages else []
                
                # ç‰¹æ®Šå¤„ç†è¡¨æ ¼å…ƒç´ 
                if 'Table' in str(type(element).__name__):
                    element_data.update(self._process_table_element(element))
                
                # ç‰¹æ®Šå¤„ç†å›¾ç‰‡å…ƒç´ 
                if 'Image' in str(type(element).__name__):
                    element_data.update(self._process_image_element(element))
                
                # æ·»åŠ ç”¨äºå‘é‡åŒ–çš„ç»„åˆæ–‡æœ¬
                element_data["vectorization_text"] = self._generate_vectorization_text(element_data)
                
                # æ·»åŠ ç”¨äºå®ä½“å…³ç³»æå–çš„ä¸Šä¸‹æ–‡
                element_data["context_info"] = self._generate_context_info(element_data, idx, len(elements))
                
                structured_elements.append(element_data)
                
            except Exception as e:
                logger.warning(f"å¤„ç†å…ƒç´  {idx} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                # å³ä½¿å•ä¸ªå…ƒç´ å¤„ç†å¤±è´¥ï¼Œä¹Ÿç»§ç»­å¤„ç†å…¶ä»–å…ƒç´ 
                continue
        
        return structured_elements
    
    def _process_table_element(self, element) -> Dict[str, Any]:
        """
        ç‰¹æ®Šå¤„ç†è¡¨æ ¼å…ƒç´ 
        
        Args:
            element: è¡¨æ ¼å…ƒç´ 
            
        Returns:
            Dict[str, Any]: è¡¨æ ¼ç‰¹æ®Šå¤„ç†ä¿¡æ¯
        """
        table_info = {
            "is_table": True,
            "table_text": str(element),
        }
        
        # å°è¯•è·å–è¡¨æ ¼çš„HTMLè¡¨ç¤º
        if hasattr(element, 'metadata') and hasattr(element.metadata, 'text_as_html'):
            table_info["table_html"] = str(element.metadata.text_as_html) if element.metadata.text_as_html else None
        
        return table_info
    
    def _process_image_element(self, element) -> Dict[str, Any]:
        """
        ç‰¹æ®Šå¤„ç†å›¾ç‰‡å…ƒç´ 
        
        Args:
            element: å›¾ç‰‡å…ƒç´ 
            
        Returns:
            Dict[str, Any]: å›¾ç‰‡ç‰¹æ®Šå¤„ç†ä¿¡æ¯
        """
        image_info = {
            "is_image": True,
            "image_description": str(element) if str(element) else "å›¾ç‰‡å†…å®¹",
        }
        
        # å¦‚æœæœ‰å›¾ç‰‡è·¯å¾„ä¿¡æ¯
        if hasattr(element, 'metadata') and hasattr(element.metadata, 'image_path'):
            image_info["image_path"] = str(element.metadata.image_path) if element.metadata.image_path else None
        
        return image_info
    
    def _generate_vectorization_text(self, element_data: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆç”¨äºå‘é‡åŒ–çš„ç»„åˆæ–‡æœ¬
        
        Args:
            element_data (Dict[str, Any]): å…ƒç´ æ•°æ®
            
        Returns:
            str: ç”¨äºå‘é‡åŒ–çš„æ–‡æœ¬
        """
        vectorization_parts = []
        
        # æ·»åŠ å…ƒç´ ç±»å‹ä¿¡æ¯
        if element_data.get("element_type_cn"):
            vectorization_parts.append(f"[{element_data['element_type_cn']}]")
        
        # æ·»åŠ ä¸»è¦æ–‡æœ¬å†…å®¹
        if element_data.get("text_content"):
            vectorization_parts.append(element_data["text_content"])
        
        # å¦‚æœæ˜¯è¡¨æ ¼ï¼Œæ·»åŠ ç»“æ„ä¿¡æ¯
        if element_data.get("is_table"):
            vectorization_parts.append("[è¡¨æ ¼æ•°æ®]")
        
        # å¦‚æœæ˜¯å›¾ç‰‡ï¼Œæ·»åŠ æè¿°ä¿¡æ¯
        if element_data.get("is_image"):
            vectorization_parts.append("[å›¾ç‰‡å†…å®¹]")
            if element_data.get("image_description"):
                vectorization_parts.append(element_data["image_description"])
        
        return " ".join(vectorization_parts)
    
    def _generate_context_info(self, element_data: Dict[str, Any], current_idx: int, total_elements: int) -> Dict[str, Any]:
        """
        ç”Ÿæˆç”¨äºå®ä½“å…³ç³»æå–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Args:
            element_data (Dict[str, Any]): å½“å‰å…ƒç´ æ•°æ®
            current_idx (int): å½“å‰å…ƒç´ ç´¢å¼•
            total_elements (int): æ€»å…ƒç´ æ•°é‡
            
        Returns:
            Dict[str, Any]: ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        context_info = {
            "position_in_document": {
                "index": current_idx,
                "relative_position": current_idx / total_elements if total_elements > 0 else 0,
                "is_beginning": current_idx < total_elements * 0.1,
                "is_middle": 0.1 <= current_idx / total_elements <= 0.9,
                "is_end": current_idx > total_elements * 0.9
            }
        }
        
        # æ·»åŠ é¡µé¢ä¸Šä¸‹æ–‡
        if element_data.get("page_number"):
            context_info["page_context"] = {
                "page_number": element_data["page_number"],
                "page_position": f"ç¬¬{element_data['page_number']}é¡µ"
            }
        
        # æ·»åŠ å…ƒç´ ç±»å‹ä¸Šä¸‹æ–‡
        context_info["type_context"] = {
            "element_type": element_data.get("element_type"),
            "is_title": "Title" in element_data.get("element_type", ""),
            "is_content": "NarrativeText" in element_data.get("element_type", ""),
            "is_structured": element_data.get("is_table", False) or element_data.get("is_image", False)
        }
        
        return context_info
    
    def _load_config(self) -> Dict[str, Any]:
        """
        åŠ è½½é¡¹ç›®é…ç½®æ–‡ä»¶
        
        Returns:
            Dict[str, Any]: é…ç½®å­—å…¸
        """
        try:
            # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆä»å½“å‰æ–‡ä»¶ä½ç½®æ¨å¯¼ï¼‰
            current_dir = Path(__file__).parent.parent.parent.parent
            config_path = current_dir / "config" / "config.yaml"
            
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                logger.info(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
                return config
            else:
                logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return {"upload": {"json_path": "./upload/json"}}
                
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return {"upload": {"json_path": "./upload/json"}}
    
    def _save_json_result(self, result: Dict[str, Any], pdf_file_path: str) -> Optional[str]:
        """
        ä¿å­˜æå–ç»“æœåˆ°JSONæ–‡ä»¶
        
        Args:
            result (Dict[str, Any]): æå–ç»“æœ
            pdf_file_path (str): åŸå§‹PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            Optional[str]: ä¿å­˜çš„JSONæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¿å­˜å¤±è´¥åˆ™è¿”å›None
        """
        try:
            # è·å–é…ç½®çš„JSONä¿å­˜è·¯å¾„
            json_path = self.config.get("upload", {}).get("json_path", "./upload/json")
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            json_dir = Path(json_path)
            json_dir.mkdir(parents=True, exist_ok=True)
            
            # ç”ŸæˆJSONæ–‡ä»¶åï¼ˆåŸºäºåŸPDFæ–‡ä»¶åï¼‰
            pdf_name = Path(pdf_file_path).stem  # ä¸åŒ…å«æ‰©å±•åçš„æ–‡ä»¶å
            json_filename = f"{pdf_name}_extracted.json"
            json_file_path = json_dir / json_filename
            
            # ä¿å­˜JSONæ–‡ä»¶
            with open(json_file_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            logger.info(f"JSONæ–‡ä»¶ä¿å­˜æˆåŠŸ: {json_file_path}")
            return str(json_file_path.absolute())
            
        except Exception as e:
            logger.error(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥: {str(e)}")
            return None


# å…¨å±€å‡½æ•°æ¥å£ï¼Œæ–¹ä¾¿å¤–éƒ¨è°ƒç”¨
def extract_pdf_content(pdf_file_path: str) -> Dict[str, Any]:
    """
    PDFå†…å®¹æå–çš„å…¨å±€å‡½æ•°æ¥å£
    
    Args:
        pdf_file_path (str): PDFæ–‡ä»¶çš„ç»å¯¹è·¯å¾„
        
    Returns:
        Dict[str, Any]: ç»“æ„åŒ–çš„JSONæ•°æ®
    """
    extractor = PdfExtractService()
    return extractor.extract_pdf_content(pdf_file_path)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import sys
    
    if len(sys.argv) > 1:
        test_pdf_path = sys.argv[1]
        try:
            result = extract_pdf_content(test_pdf_path)
            print("âœ… AIæ ¸å¿ƒPDFæå–æˆåŠŸ!")
            print(f"ğŸ“„ æ–‡æ¡£åç§°: {result['document_info']['file_name']}")
            print(f"ğŸ“Š æœ‰æ•ˆå…ƒç´ æ•°: {len(result['elements'])}")
            print(f"ğŸ“– æ€»é¡µæ•°: {result['document_info']['total_pages']}")
            print(f"ğŸ’¾ æ–‡æ¡£å“ˆå¸Œ: {result['document_info']['file_hash'][:8]}...")
            
            # æ˜¾ç¤ºå‰3ä¸ªå…ƒç´ ç¤ºä¾‹
            print("\nğŸ¯ AIæ ¸å¿ƒå…ƒç´ ç¤ºä¾‹:")
            for i, elem in enumerate(result['elements'][:3]):
                print(f"  å…ƒç´ {i+1}:")
                print(f"    - ID: {elem['element_id']}")
                print(f"    - é¡µç : {elem.get('page_number', 'N/A')}")
                print(f"    - å‘é‡åŒ–æ–‡æœ¬: {elem['vectorization_text'][:50]}...")
            
            if result.get('saved_json_path'):
                print(f"\nğŸ’¾ JSONå·²è‡ªåŠ¨ä¿å­˜åˆ°: {result['saved_json_path']}")
            
        except Exception as e:
            print(f"âŒ æå–å¤±è´¥: {str(e)}")
    else:
        print("ä½¿ç”¨æ–¹æ³•: python PdfExtractService.py <pdf_file_path>")