"""
æ™ºèƒ½æ£€ç´¢æœåŠ¡
è´Ÿè´£åŸºäºå‘é‡å’ŒçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½æœç´¢åŠŸèƒ½
"""

import logging
import yaml
import json
import numpy as np
from typing import Optional, Dict, Any, List, Union
from datetime import datetime
import requests
import re

from utils.MySQLManager import MySQLManager
from utils.MilvusManager import MilvusManager
from utils.Neo4jManager import Neo4jManager
from sentence_transformers import SentenceTransformer


class SearchService:
    """æ™ºèƒ½æ£€ç´¢æœåŠ¡ç±»"""
    
    def __init__(self, config_path: str = 'config/config.yaml'):
        """
        åˆå§‹åŒ–æœç´¢æœåŠ¡
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.logger = logging.getLogger(__name__)
        
        # åŠ è½½é…ç½®
        self._load_configs()
        
        # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        self.mysql_manager = MySQLManager()
        self.milvus_manager = MilvusManager()
        self.neo4j_manager = Neo4jManager()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._init_models()
    
    def _load_configs(self) -> None:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            # åŠ è½½ä¸»é…ç½®
            with open(self.config_path, 'r', encoding='utf-8') as file:
                self.config = yaml.safe_load(file)
            
            # åŠ è½½æ¨¡å‹é…ç½®
            with open('config/model.yaml', 'r', encoding='utf-8') as file:
                self.model_config = yaml.safe_load(file)
            
            # åŠ è½½æç¤ºè¯é…ç½®
            with open('config/prompt.yaml', 'r', encoding='utf-8') as file:
                self.prompt_config = yaml.safe_load(file)
            
            self.logger.info("æœç´¢æœåŠ¡é…ç½®åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"åŠ è½½æœç´¢æœåŠ¡é…ç½®å¤±è´¥: {str(e)}")
            raise
    
    def _init_models(self) -> None:
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
            model_name = self.model_config['embedding']['model_name']
            self.embedding_model = SentenceTransformer(
                model_name,
                cache_folder=self.model_config['embedding']['cache_dir']
            )
            
            self.logger.info(f"åµŒå…¥æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {model_name}")
            
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–æ¨¡å‹å¤±è´¥: {str(e)}")
            raise
    
    def _get_text_embedding(self, text: str) -> Optional[List[float]]:
        """
        è·å–æ–‡æœ¬å‘é‡
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            Optional[List[float]]: æ–‡æœ¬å‘é‡ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # æ–‡æœ¬é¢„å¤„ç†
            processed_text = self._preprocess_text(text)
            
            # ç”Ÿæˆå‘é‡
            embedding = self.embedding_model.encode(
                processed_text,
                normalize_embeddings=self.model_config['embedding']['normalize']
            )
            
            return embedding.tolist()
            
        except Exception as e:
            self.logger.error(f"è·å–æ–‡æœ¬å‘é‡å¤±è´¥: {str(e)}")
            return None
    
    def _preprocess_text(self, text: str) -> str:
        """
        æ–‡æœ¬é¢„å¤„ç†
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            str: é¢„å¤„ç†åçš„æ–‡æœ¬
        """
        try:
            preprocessing_config = self.model_config['embedding']['preprocessing']
            
            # æ¸…ç†æ–‡æœ¬
            if preprocessing_config.get('clean_text', True):
                text = re.sub(r'\s+', ' ', text)  # åˆå¹¶å¤šä¸ªç©ºç™½å­—ç¬¦
                text = text.strip()
            
            # è½¬å°å†™
            if preprocessing_config.get('lowercase', False):
                text = text.lower()
            
            # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
            if preprocessing_config.get('remove_special_chars', False):
                text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)
            
            # é™åˆ¶é•¿åº¦
            max_length = preprocessing_config.get('max_chunk_size', 500)
            if len(text) > max_length:
                text = text[:max_length]
            
            return text
            
        except Exception as e:
            self.logger.error(f"æ–‡æœ¬é¢„å¤„ç†å¤±è´¥: {str(e)}")
            return text
    
    def _call_deepseek_api(self, prompt: str, max_tokens: Optional[int] = None) -> Optional[str]:
        """
        è°ƒç”¨DeepSeek API
        
        Args:
            prompt: æç¤ºè¯
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            
        Returns:
            Optional[str]: APIå“åº”å†…å®¹ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            deepseek_config = self.model_config['deepseek']
            
            headers = {
                'Authorization': f"Bearer {deepseek_config['api_key']}",
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': deepseek_config['model_name'],
                'messages': [
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': max_tokens or deepseek_config['max_tokens'],
                'temperature': deepseek_config['temperature'],
                'top_p': deepseek_config['top_p']
            }
            
            response = requests.post(
                f"{deepseek_config['api_url']}/chat/completions",
                headers=headers,
                json=data,
                timeout=deepseek_config['timeout']
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                self.logger.error(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {response.status_code}, {response.text}")
                return None
                
        except Exception as e:
            self.logger.error(f"è°ƒç”¨DeepSeek APIå¤±è´¥: {str(e)}")
            return None
    
    def _parse_deepseek_json_response(self, response: str) -> Optional[Dict[str, Any]]:
        """
        è§£æDeepSeek APIè¿”å›çš„JSONå“åº” - å¢å¼ºå®¹é”™å¤„ç†
        
        Args:
            response: DeepSeek APIçš„åŸå§‹å“åº”
            
        Returns:
            Optional[Dict[str, Any]]: è§£æåçš„JSONå¯¹è±¡ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not response or not response.strip():
            return None
            
        try:
            # æ–¹æ³•1ï¼šç›´æ¥è§£æï¼ˆé€‚ç”¨äºæ ‡å‡†JSONå“åº”ï¼‰
            return json.loads(response.strip())
        except json.JSONDecodeError:
            pass
        
        try:
            # æ–¹æ³•2ï¼šæå–JSONå—ï¼ˆé€‚ç”¨äºåŒ…å«è§£é‡Šæ–‡å­—çš„å“åº”ï¼‰
            import re
            
            # æŸ¥æ‰¾JSONå—æ¨¡å¼ï¼š{...}
            json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
            matches = re.findall(json_pattern, response, re.DOTALL)
            
            for match in matches:
                try:
                    return json.loads(match.strip())
                except json.JSONDecodeError:
                    continue
                    
        except Exception:
            pass
        
        try:
            # æ–¹æ³•3ï¼šé€è¡ŒæŸ¥æ‰¾JSONï¼ˆé€‚ç”¨äºå¤šè¡Œå“åº”ï¼‰
            lines = response.strip().split('\n')
            json_lines = []
            in_json = False
            
            for line in lines:
                line = line.strip()
                if line.startswith('{'):
                    in_json = True
                    json_lines = [line]
                elif in_json:
                    json_lines.append(line)
                    if line.endswith('}'):
                        try:
                            json_str = '\n'.join(json_lines)
                            return json.loads(json_str)
                        except json.JSONDecodeError:
                            in_json = False
                            json_lines = []
                            
        except Exception:
            pass
        
        # æ–¹æ³•4ï¼šæ‰‹åŠ¨æ„å»ºJSONï¼ˆåº”æ€¥æ–¹æ¡ˆï¼‰
        try:
            # å°è¯•ä»å“åº”ä¸­æå–å…³é”®ä¿¡æ¯
            result = {}
            
            # æŸ¥æ‰¾æ ¸å¿ƒå…³é”®è¯
            if '"core_keywords"' in response:
                # æå–core_keywordså€¼
                import re
                pattern = r'"core_keywords":\s*"([^"]*)"'
                match = re.search(pattern, response)
                if match:
                    result['core_keywords'] = match.group(1)
                    result['refined_query'] = match.group(1)  # ä½¿ç”¨æ ¸å¿ƒå…³é”®è¯ä½œä¸ºä¼˜åŒ–æŸ¥è¯¢
                    result['search_intent'] = f"æŸ¥æ‰¾{match.group(1)}ç›¸å…³ä¿¡æ¯"
                    return result
                    
        except Exception:
            pass
        
        # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
        self.logger.error(f"JSONè§£æå®Œå…¨å¤±è´¥ï¼Œå“åº”å†…å®¹: '{response[:500]}...'")
        return None
    
    def _optimize_query_for_retrieval(self, user_query: str) -> Dict[str, Any]:
        """
        æŸ¥è¯¢ä¼˜åŒ– - ä½¿ç”¨DeepSeekåˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œæå–æ ¸å¿ƒæ£€ç´¢å…³é”®è¯
        
        Args:
            user_query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            
        Returns:
            Dict[str, Any]: åŒ…å«ä¼˜åŒ–ç»“æœçš„å­—å…¸
        """
        try:
            # æ„å»ºæŸ¥è¯¢ä¼˜åŒ–æç¤ºè¯
            prompt_template = self.prompt_config['query_optimization']['query_rewrite']
            prompt = prompt_template.format(user_query=user_query)
            
            # è°ƒç”¨DeepSeek APIè¿›è¡ŒæŸ¥è¯¢åˆ†æ
            response = self._call_deepseek_api(prompt)
            
            if response:
                try:
                    # ğŸ”§ æ”¹è¿›çš„JSONè§£æé€»è¾‘ - æ”¯æŒå¤šç§å“åº”æ ¼å¼
                    optimization_result = self._parse_deepseek_json_response(response)
                    
                    # éªŒè¯å¿…è¦å­—æ®µ
                    if optimization_result and 'refined_query' in optimization_result and optimization_result['refined_query'].strip():
                        self.logger.info(f"æŸ¥è¯¢ä¼˜åŒ–æˆåŠŸ: '{user_query}' -> '{optimization_result['refined_query']}'")
                        return {
                            'success': True,
                            'original_query': user_query,
                            'optimized_query': optimization_result['refined_query'],
                            'core_keywords': optimization_result.get('core_keywords', ''),
                            'search_intent': optimization_result.get('search_intent', ''),
                            'removed_noise': optimization_result.get('removed_noise', [])
                        }
                    else:
                        self.logger.warning("DeepSeekè¿”å›çš„ä¼˜åŒ–ç»“æœæ— æ•ˆï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢")
                        
                except Exception as e:
                    self.logger.error(f"æŸ¥è¯¢ä¼˜åŒ–å¤±è´¥: {str(e)}, åŸå§‹å“åº”: {response[:200]}...")
            
            # é™çº§å¤„ç†ï¼šè¿”å›åŸå§‹æŸ¥è¯¢
            return {
                'success': False,
                'original_query': user_query,
                'optimized_query': user_query,
                'core_keywords': user_query,
                'search_intent': 'åŸå§‹æŸ¥è¯¢',
                'removed_noise': []
            }
            
        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢ä¼˜åŒ–å¤±è´¥: {str(e)}")
            # é™çº§å¤„ç†ï¼šè¿”å›åŸå§‹æŸ¥è¯¢
            return {
                'success': False,
                'original_query': user_query,
                'optimized_query': user_query,
                'core_keywords': user_query,
                'search_intent': 'æŸ¥è¯¢ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢',
                'removed_noise': []
            }
    
    def vector_search(self, query: str, top_k: int = 10, filters: Optional[Dict] = None, optimize_query: bool = True) -> List[Dict]:
        """
        å‘é‡ç›¸ä¼¼æ€§æœç´¢ - æ”¯æŒæŸ¥è¯¢ä¼˜åŒ–
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            filters: è¿‡æ»¤æ¡ä»¶
            optimize_query: æ˜¯å¦å¯ç”¨æŸ¥è¯¢ä¼˜åŒ–ï¼ˆé»˜è®¤Trueï¼‰
            
        Returns:
            List[Dict]: æœç´¢ç»“æœ
        """
        try:
            # ğŸ¯ æŸ¥è¯¢ä¼˜åŒ–ï¼šåœ¨å‘é‡åŒ–ä¹‹å‰å…ˆåˆ†æå¹¶ä¼˜åŒ–æŸ¥è¯¢
            # æ£€æŸ¥é…ç½®æ˜¯å¦å¯ç”¨æŸ¥è¯¢ä¼˜åŒ–
            query_optimization_enabled = self.model_config.get('query_optimization', {}).get('enabled', True)
            
            if optimize_query and query_optimization_enabled:
                optimization_result = self._optimize_query_for_retrieval(query)
                search_query = optimization_result['optimized_query']
                
                # è®°å½•ä¼˜åŒ–ä¿¡æ¯
                log_details = self.model_config.get('query_optimization', {}).get('log_optimization_details', True)
                if log_details:
                    if optimization_result['success']:
                        self.logger.info(f"âœ… æŸ¥è¯¢ä¼˜åŒ–: '{query}' -> '{search_query}'")
                    else:
                        self.logger.info(f"âš ï¸ æŸ¥è¯¢ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢: '{query}'")
            else:
                search_query = query
                optimization_result = None
                if optimize_query and not query_optimization_enabled:
                    self.logger.info("ğŸ“´ æŸ¥è¯¢ä¼˜åŒ–å·²åœ¨é…ç½®ä¸­ç¦ç”¨")
            
            # è·å–æŸ¥è¯¢å‘é‡ï¼ˆä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢ï¼‰
            query_vector = self._get_text_embedding(search_query)
            if not query_vector:
                return []
            
            # æ„å»ºè¿‡æ»¤è¡¨è¾¾å¼
            expr = None
            if filters:
                conditions = []
                if 'document_id' in filters:
                    conditions.append(f"document_id == {filters['document_id']}")
                if 'file_type' in filters:
                    # éœ€è¦é€šè¿‡document_idå…³è”æŸ¥è¯¢æ–‡ä»¶ç±»å‹
                    pass
                
                if conditions:
                    expr = " and ".join(conditions)
            
            # æ‰§è¡Œå‘é‡æœç´¢
            results = self.milvus_manager.search_vectors(
                query_vectors=[query_vector],
                top_k=top_k,
                expr=expr
            )
            
            # è·å–å…³è”çš„æ–‡æ¡£ä¿¡æ¯
            enhanced_results = []
            for result in results:
                # è·å–æ–‡æ¡£ä¿¡æ¯
                doc_info = self.mysql_manager.execute_query(
                    "SELECT filename, file_type FROM documents WHERE id = :doc_id",
                    {'doc_id': result['document_id']}
                )
                
                if doc_info:
                    result['document_info'] = doc_info[0]
                
                # ğŸ”¥ æ·»åŠ chunk_idç”¨äºå¤šæ¨¡æ€å†…å®¹å…³è”
                result['chunk_id'] = result['id']  # Milvusçš„idå°±æ˜¯document_chunksè¡¨çš„ä¸»é”®
                
                # ğŸ¯ ä¸ºæ¯ä¸ªç»“æœæ·»åŠ æŸ¥è¯¢ä¼˜åŒ–ä¿¡æ¯
                if optimize_query and optimization_result:
                    result['query_optimization'] = {
                        'original_query': optimization_result['original_query'],
                        'optimized_query': optimization_result['optimized_query'],
                        'optimization_applied': optimization_result['success']
                    }
                
                enhanced_results.append(result)
            
            # æ›´æ–°æ—¥å¿—ä¿¡æ¯
            if optimize_query and optimization_result and optimization_result['success']:
                self.logger.info(f"å‘é‡æœç´¢å®Œæˆï¼ŒåŸå§‹æŸ¥è¯¢: '{query}' -> ä¼˜åŒ–æŸ¥è¯¢: '{search_query}'ï¼Œè¿”å›{len(enhanced_results)}ä¸ªç»“æœ")
            else:
                self.logger.info(f"å‘é‡æœç´¢å®Œæˆï¼ŒæŸ¥è¯¢: '{query}'ï¼Œè¿”å›{len(enhanced_results)}ä¸ªç»“æœ")
            
            return enhanced_results
            
        except Exception as e:
            self.logger.error(f"å‘é‡æœç´¢å¤±è´¥: {str(e)}")
            return []
    
    def graph_search(self, entity_name: str, relationship_types: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        çŸ¥è¯†å›¾è°±æœç´¢
        
        Args:
            entity_name: å®ä½“åç§°
            relationship_types: å…³ç³»ç±»å‹åˆ—è¡¨
            
        Returns:
            Dict[str, Any]: æœç´¢ç»“æœ
        """
        try:
            # æŸ¥æ‰¾å®ä½“
            entities = self.neo4j_manager.find_nodes(
                label="Entity",
                properties={"name": entity_name}
            )
            
            if not entities:
                return {
                    'entity': None,
                    'neighbors': [],
                    'relationships': []
                }
            
            entity = entities[0]
            entity_id = entity['node_id']
            
            # è·å–é‚»å±…èŠ‚ç‚¹
            neighbors = self.neo4j_manager.get_node_neighbors(
                entity_id,
                relationship_types
            )
            
            # è·å–ç›¸å…³å…³ç³»
            relationships = []
            if relationship_types:
                for rel_type in relationship_types:
                    rels = self.neo4j_manager.find_relationships(
                        relationship_type=rel_type,
                        start_label="Entity"
                    )
                    relationships.extend(rels)
            
            result = {
                'entity': entity,
                'neighbors': neighbors,
                'relationships': relationships
            }
            
            self.logger.info(f"çŸ¥è¯†å›¾è°±æœç´¢å®Œæˆï¼Œå®ä½“: {entity_name}")
            return result
            
        except Exception as e:
            self.logger.error(f"çŸ¥è¯†å›¾è°±æœç´¢å¤±è´¥: {str(e)}")
            return {
                'entity': None,
                'neighbors': [],
                'relationships': []
            }
    
    def hybrid_search(self, query: str, top_k: int = 10, 
                     enable_graph: bool = True, 
                     filters: Optional[Dict] = None) -> Dict[str, Any]:
        """
        æ··åˆæœç´¢ï¼ˆå‘é‡æœç´¢ + çŸ¥è¯†å›¾è°±æœç´¢ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            enable_graph: æ˜¯å¦å¯ç”¨çŸ¥è¯†å›¾è°±æœç´¢
            filters: è¿‡æ»¤æ¡ä»¶
            
        Returns:
            Dict[str, Any]: æ··åˆæœç´¢ç»“æœ
        """
        try:
            result = {
                'query': query,
                'vector_results': [],
                'graph_results': {},
                'combined_results': []
            }
            
            # ğŸ¯ å‘é‡æœç´¢ - å¯ç”¨æŸ¥è¯¢ä¼˜åŒ–
            vector_results = self.vector_search(query, top_k, filters, optimize_query=True)
            result['vector_results'] = vector_results
            
            # çŸ¥è¯†å›¾è°±æœç´¢
            if enable_graph:
                # ğŸ¯ ä»ä¼˜åŒ–æŸ¥è¯¢æˆ–åŸå§‹æŸ¥è¯¢ä¸­æå–å®ä½“
                # å¦‚æœå‘é‡æœç´¢æœ‰ä¼˜åŒ–ç»“æœï¼Œä¼˜å…ˆä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢è¿›è¡Œå®ä½“æå–
                if vector_results and len(vector_results) > 0 and 'query_optimization' in vector_results[0]:
                    optimization_info = vector_results[0]['query_optimization']
                    if optimization_info['optimization_applied']:
                        entity_query = optimization_info['optimized_query']
                        self.logger.info(f"ä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢è¿›è¡Œå®ä½“æå–: '{entity_query}'")
                    else:
                        entity_query = query
                else:
                    entity_query = query
                
                entities = self._extract_entities_from_query(entity_query)
                graph_results = {}
                
                for entity in entities:
                    entity_result = self.graph_search(entity)
                    if entity_result['entity']:
                        graph_results[entity] = entity_result
                
                result['graph_results'] = graph_results
            
            # åˆå¹¶ç»“æœ
            combined_results = self._combine_search_results(vector_results, result['graph_results'])
            result['combined_results'] = combined_results
            
            self.logger.info(f"æ··åˆæœç´¢å®Œæˆï¼ŒæŸ¥è¯¢: {query}")
            return result
            
        except Exception as e:
            self.logger.error(f"æ··åˆæœç´¢å¤±è´¥: {str(e)}")
            return {
                'query': query,
                'vector_results': [],
                'graph_results': {},
                'combined_results': []
            }
    
    def _extract_entities_from_query(self, query: str) -> List[str]:
        """
        ä»æŸ¥è¯¢ä¸­æå–å®ä½“
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            List[str]: æå–çš„å®ä½“åˆ—è¡¨
        """
        try:
            # ä½¿ç”¨DeepSeek APIè¿›è¡Œå®ä½“è¯†åˆ«
            prompt = self.prompt_config['entity_recognition']['ner_extraction'].format(
                text_content=query
            )
            
            response = self._call_deepseek_api(prompt)
            if response:
                # ğŸ”§ ä½¿ç”¨å¢å¼ºçš„JSONè§£ææ–¹æ³•
                try:
                    entities_data = self._parse_deepseek_json_response(response)
                    if entities_data:
                        all_entities = []
                        for entity_type, entities in entities_data.items():
                            if isinstance(entities, list):
                                all_entities.extend(entities)
                        return all_entities
                    else:
                        self.logger.warning(f"æ— æ³•è§£æå®ä½“è¯†åˆ«ç»“æœ: {response[:200]}...")
                except Exception as e:
                    self.logger.error(f"å®ä½“è¯†åˆ«JSONè§£æå¤±è´¥: {str(e)}, å“åº”: {response[:200]}...")
            
            return []
            
        except Exception as e:
            self.logger.error(f"æå–å®ä½“å¤±è´¥: {str(e)}")
            return []
    
    def _combine_search_results(self, vector_results: List[Dict], graph_results: Dict) -> List[Dict]:
        """
        åˆå¹¶æœç´¢ç»“æœ
        
        Args:
            vector_results: å‘é‡æœç´¢ç»“æœ
            graph_results: çŸ¥è¯†å›¾è°±æœç´¢ç»“æœ
            
        Returns:
            List[Dict]: åˆå¹¶åçš„ç»“æœ
        """
        try:
            combined = []
            
            # æ·»åŠ å‘é‡æœç´¢ç»“æœ
            for result in vector_results:
                combined_item = {
                    'type': 'vector',
                    'score': result['score'],
                    'content': result['content'],
                    'document_id': result['document_id'],
                    'chunk_index': result['chunk_index'],
                    'metadata': result.get('metadata', {}),
                    'document_info': result.get('document_info', {})
                }
                combined.append(combined_item)
            
            # æ·»åŠ çŸ¥è¯†å›¾è°±ç»“æœ
            for entity_name, graph_data in graph_results.items():
                if graph_data['entity']:
                    combined_item = {
                        'type': 'graph',
                        'score': 1.0,  # å›¾æœç´¢ç»“æœç»™äºˆå›ºå®šåˆ†æ•°
                        'entity': entity_name,
                        'entity_properties': graph_data['entity']['properties'],
                        'neighbors': graph_data['neighbors'],
                        'relationships': graph_data['relationships']
                    }
                    combined.append(combined_item)
            
            # æŒ‰åˆ†æ•°æ’åº
            combined.sort(key=lambda x: x['score'], reverse=True)
            
            return combined
            
        except Exception as e:
            self.logger.error(f"åˆå¹¶æœç´¢ç»“æœå¤±è´¥: {str(e)}")
            return []
    
    def question_answering(self, question: str, context_limit: int = 5) -> Dict[str, Any]:
        """
        åŸºäºæ£€ç´¢çš„é—®ç­” - æ”¯æŒå¤šæ¨¡æ€å†…å®¹è¿”å›
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            context_limit: ä¸Šä¸‹æ–‡æ–‡æ¡£æ•°é‡é™åˆ¶
            
        Returns:
            Dict[str, Any]: é—®ç­”ç»“æœï¼ŒåŒ…å«å¤šæ¨¡æ€æ•°æ®
        """
        try:
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            search_results = self.hybrid_search(question, top_k=context_limit)
            
            # ğŸ¯ æå–å¤šæ¨¡æ€å†…å®¹å’Œå‡†å¤‡ä¸Šä¸‹æ–‡
            relevant_docs = []
            multimodal_content = {
                'images': [],
                'tables': [],
                'charts': []
            }
            
            for result in search_results['combined_results'][:context_limit]:
                if result['type'] == 'vector':
                    relevant_docs.append(result['content'])
                    
                    # ğŸ” ä»MySQLè·å–å®Œæ•´çš„å¤šæ¨¡æ€æ•°æ®
                    if 'chunk_id' in result:
                        chunk_multimodal = self._get_chunk_multimodal_content(result['chunk_id'])
                        if chunk_multimodal:
                            multimodal_content['images'].extend(chunk_multimodal.get('img', []))
                            multimodal_content['tables'].extend(chunk_multimodal.get('table', []))
                            multimodal_content['charts'].extend(chunk_multimodal.get('chars', []))
                            
                elif result['type'] == 'graph':
                    # å°†å›¾ä¿¡æ¯è½¬æ¢ä¸ºæ–‡æœ¬æè¿°
                    graph_desc = f"å®ä½“: {result['entity']}, é‚»å±…: {len(result['neighbors'])}ä¸ª"
                    relevant_docs.append(graph_desc)
            
            context = "\n\n".join(relevant_docs)
            
            # ğŸ¯ æ„å»ºå¢å¼ºçš„é—®ç­”æç¤ºè¯ï¼ˆåŒ…å«å¤šæ¨¡æ€ä¿¡æ¯ï¼‰
            multimodal_context = self._build_multimodal_context(multimodal_content)
            enhanced_context = context
            if multimodal_context:
                enhanced_context += f"\n\nç›¸å…³å¤šåª’ä½“å†…å®¹:\n{multimodal_context}"
            
            prompt = self.prompt_config['question_answering']['doc_qa'].format(
                relevant_docs=enhanced_context,
                question=question
            )
            
            # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ
            answer = self._call_deepseek_api(prompt)
            
            # ğŸ¯ æå–æŸ¥è¯¢ä¼˜åŒ–ä¿¡æ¯
            query_optimization_info = None
            if (search_results.get('vector_results') and 
                len(search_results['vector_results']) > 0 and 
                'query_optimization' in search_results['vector_results'][0]):
                query_optimization_info = search_results['vector_results'][0]['query_optimization']
            
            result = {
                'question': question,
                'answer': answer,
                'context': relevant_docs,
                'search_results': search_results,
                'multimodal_content': multimodal_content,  # ğŸ”¥ æ–°å¢å¤šæ¨¡æ€å†…å®¹
                'query_optimization': query_optimization_info,  # ğŸ¯ æ·»åŠ æŸ¥è¯¢ä¼˜åŒ–ä¿¡æ¯
                'timestamp': datetime.now().isoformat()
            }
            
            # ğŸ¯ æ›´æ–°æ—¥å¿—ï¼Œæ˜¾ç¤ºæŸ¥è¯¢ä¼˜åŒ–æ•ˆæœå’Œå¤šæ¨¡æ€å†…å®¹
            multimodal_stats = f"å›¾ç‰‡{len(multimodal_content['images'])}ä¸ª, è¡¨æ ¼{len(multimodal_content['tables'])}ä¸ª, å›¾è¡¨{len(multimodal_content['charts'])}ä¸ª"
            
            if query_optimization_info and query_optimization_info['optimization_applied']:
                self.logger.info(f"é—®ç­”å®Œæˆï¼ŒåŸå§‹é—®é¢˜: '{question}' -> ä¼˜åŒ–æŸ¥è¯¢: '{query_optimization_info['optimized_query']}', å¤šæ¨¡æ€å†…å®¹: {multimodal_stats}")
            else:
                self.logger.info(f"é—®ç­”å®Œæˆï¼Œé—®é¢˜: '{question}', å¤šæ¨¡æ€å†…å®¹: {multimodal_stats}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"é—®ç­”å¤±è´¥: {str(e)}")
            return {
                'question': question,
                'answer': f"æŠ±æ­‰ï¼Œå›ç­”æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}",
                'context': [],
                'search_results': {},
                'timestamp': datetime.now().isoformat()
            }
    
    def semantic_search(self, query: str, search_type: str = "all", 
                       top_k: int = 10, filters: Optional[Dict] = None) -> Dict[str, Any]:
        """
        è¯­ä¹‰æœç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            search_type: æœç´¢ç±»å‹ (vector, graph, all)
            top_k: è¿”å›ç»“æœæ•°é‡
            filters: è¿‡æ»¤æ¡ä»¶
            
        Returns:
            Dict[str, Any]: æœç´¢ç»“æœ
        """
        try:
            if search_type == "vector":
                results = self.vector_search(query, top_k, filters)
                return {
                    'search_type': 'vector',
                    'results': results,
                    'total': len(results)
                }
            elif search_type == "graph":
                entities = self._extract_entities_from_query(query)
                graph_results = {}
                for entity in entities:
                    graph_results[entity] = self.graph_search(entity)
                
                return {
                    'search_type': 'graph',
                    'results': graph_results,
                    'total': len(graph_results)
                }
            else:  # all
                results = self.hybrid_search(query, top_k, True, filters)
                return {
                    'search_type': 'hybrid',
                    'results': results,
                    'total': len(results['combined_results'])
                }
                
        except Exception as e:
            self.logger.error(f"è¯­ä¹‰æœç´¢å¤±è´¥: {str(e)}")
            return {
                'search_type': search_type,
                'results': [],
                'total': 0,
                'error': str(e)
            }
    
    def get_search_suggestions(self, partial_query: str, limit: int = 5) -> List[str]:
        """
        è·å–æœç´¢å»ºè®®
        
        Args:
            partial_query: éƒ¨åˆ†æŸ¥è¯¢æ–‡æœ¬
            limit: å»ºè®®æ•°é‡é™åˆ¶
            
        Returns:
            List[str]: æœç´¢å»ºè®®åˆ—è¡¨
        """
        try:
            # ä»æ•°æ®åº“ä¸­è·å–ç›¸ä¼¼çš„æ–‡æ¡£æ ‡é¢˜æˆ–å†…å®¹ç‰‡æ®µ
            query = """
            SELECT DISTINCT content
            FROM document_chunks
            WHERE content LIKE :pattern
            LIMIT :limit
            """
            
            pattern = f"%{partial_query}%"
            results = self.mysql_manager.execute_query(
                query, 
                {'pattern': pattern, 'limit': limit}
            )
            
            suggestions = []
            for result in results:
                content = result['content']
                # æå–åŒ…å«æŸ¥è¯¢è¯çš„å¥å­
                sentences = content.split('ã€‚')
                for sentence in sentences:
                    if partial_query in sentence and len(sentence.strip()) > 0:
                        suggestions.append(sentence.strip())
                        if len(suggestions) >= limit:
                            break
                if len(suggestions) >= limit:
                    break
            
            return suggestions[:limit]
            
        except Exception as e:
            self.logger.error(f"è·å–æœç´¢å»ºè®®å¤±è´¥: {str(e)}")
            return []
    
    def _get_chunk_multimodal_content(self, chunk_id: int) -> Optional[Dict[str, Any]]:
        """
        ä»MySQLè·å–æ–‡æ¡£å—çš„å¤šæ¨¡æ€å†…å®¹
        
        Args:
            chunk_id: æ–‡æ¡£å—ID
            
        Returns:
            Optional[Dict[str, Any]]: å¤šæ¨¡æ€å†…å®¹ï¼ŒåŒ…å«imgã€tableã€charsç­‰
        """
        try:
            query = """
            SELECT content 
            FROM document_chunks 
            WHERE id = :chunk_id
            """
            
            result = self.mysql_manager.execute_query(query, {'chunk_id': chunk_id})
            
            if result and len(result) > 0:
                content_json = result[0]['content']
                
                # è§£æJSONå†…å®¹
                if isinstance(content_json, str):
                    content_data = json.loads(content_json)
                else:
                    content_data = content_json
                
                # æå–ç»“æ„åŒ–æ•°æ®
                structured_data = {
                    'img': content_data.get('img', []),
                    'table': content_data.get('table', []),
                    'chars': content_data.get('chars', [])
                }
                
                return structured_data
                
        except Exception as e:
            self.logger.error(f"è·å–å—å¤šæ¨¡æ€å†…å®¹å¤±è´¥: {str(e)}")
            
        return None
    
    def _build_multimodal_context(self, multimodal_content: Dict[str, List]) -> str:
        """
        æ„å»ºå¤šæ¨¡æ€å†…å®¹çš„æ–‡æœ¬æè¿°ï¼Œç”¨äºå¢å¼ºä¸Šä¸‹æ–‡
        
        Args:
            multimodal_content: å¤šæ¨¡æ€å†…å®¹å­—å…¸
            
        Returns:
            str: å¤šæ¨¡æ€å†…å®¹çš„æ–‡æœ¬æè¿°
        """
        try:
            context_parts = []
            
            # å¤„ç†å›¾ç‰‡ä¿¡æ¯
            if multimodal_content['images']:
                img_descriptions = []
                for img in multimodal_content['images']:
                    desc = f"å›¾ç‰‡ {img.get('element_id', '')}"
                    if img.get('description'):
                        desc += f": {img['description']}"
                    if img.get('file_path'):
                        desc += f" (è·¯å¾„: {img['file_path']})"
                    img_descriptions.append(desc)
                
                if img_descriptions:
                    context_parts.append(f"ç›¸å…³å›¾ç‰‡: {'; '.join(img_descriptions)}")
            
            # å¤„ç†è¡¨æ ¼ä¿¡æ¯
            if multimodal_content['tables']:
                table_descriptions = []
                for table in multimodal_content['tables']:
                    desc = f"è¡¨æ ¼ {table.get('element_id', '')}"
                    if table.get('title'):
                        desc += f": {table['title']}"
                    if table.get('summary'):
                        desc += f" - {table['summary']}"
                    elif table.get('table_data'):
                        # ç®€åŒ–æ˜¾ç¤ºè¡¨æ ¼ç»“æ„
                        rows = len(table['table_data'])
                        cols = len(table['table_data'][0]) if rows > 0 else 0
                        desc += f" ({rows}è¡Œx{cols}åˆ—)"
                    table_descriptions.append(desc)
                
                if table_descriptions:
                    context_parts.append(f"ç›¸å…³è¡¨æ ¼: {'; '.join(table_descriptions)}")
            
            # å¤„ç†å›¾è¡¨ä¿¡æ¯
            if multimodal_content['charts']:
                chart_descriptions = []
                for chart in multimodal_content['charts']:
                    desc = f"å›¾è¡¨ {chart.get('element_id', '')}"
                    if chart.get('description'):
                        desc += f": {chart['description']}"
                    chart_descriptions.append(desc)
                
                if chart_descriptions:
                    context_parts.append(f"ç›¸å…³å›¾è¡¨: {'; '.join(chart_descriptions)}")
            
            return "\n".join(context_parts)
            
        except Exception as e:
            self.logger.error(f"æ„å»ºå¤šæ¨¡æ€ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}")
            return ""