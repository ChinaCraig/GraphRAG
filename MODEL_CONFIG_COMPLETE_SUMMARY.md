# çŸ¥è¯†å›¾è°±æ¨¡å‹é…ç½®å®Œæˆæ€»ç»“

## ğŸ“‹ ä»»åŠ¡æ¦‚è¿°

åº”ç”¨æˆ·è¦æ±‚ï¼Œå®Œå–„äº†é‡æ„åçŸ¥è¯†å›¾è°±çš„æ¨¡å‹é…ç½®å’Œä¸‹è½½æœºåˆ¶ï¼Œè§£å†³äº†ä»¥ä¸‹ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š
1. **éœ€è¦ç”¨åˆ°æ¨¡å‹ä¹ˆï¼Ÿ** - æ˜¯çš„ï¼Œéœ€è¦å¤šä¸ªAIæ¨¡å‹
2. **æ¨¡å‹ä¸ºä»€ä¹ˆæ²¡æœ‰æ”¾åœ¨é…ç½®æ–‡ä»¶ä¸­ï¼Ÿ** - å·²è¡¥å……åˆ°`config/model.yaml`
3. **ä¸ºä»€ä¹ˆæ²¡æœ‰åˆ›å»ºä¸‹è½½è„šæœ¬ï¼Ÿ** - å·²åˆ›å»ºä¸“é—¨çš„ä¸‹è½½è„šæœ¬

## âœ… å·²å®Œæˆçš„å·¥ä½œ

### 1) ğŸ“ å®Œå–„æ¨¡å‹é…ç½®æ–‡ä»¶

**æ–‡ä»¶**: `config/model.yaml`

**æ–°å¢é…ç½®**:
```yaml
# çŸ¥è¯†å›¾è°±æ¨¡å‹é…ç½® (æ–°å¢)
knowledge_graph:
  # ç»Ÿè®¡å¼NERæ¨¡å‹é…ç½®
  ner:
    enabled: true
    model_name: "bert-base-chinese"
    device: "cpu"
    cache_dir: "./models"
    max_length: 512
    batch_size: 16
    confidence_thresholds:
      high: 0.9
      medium: 0.7  
      low: 0.5
    fallback_to_rules: true
    
  # å®ä½“é“¾æ¥æ¨¡å‹é…ç½®  
  entity_linking:
    enabled: true
    bi_encoder: "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
    cross_encoder: "BAAI/bge-reranker-large"
    cache_dir: "./models"
    device: "cpu"
    candidate_top_k: 10
    rerank_threshold: 0.7
    nil_threshold: 0.5
    context_window: 50
    
  # å…³ç³»æŠ½å–æ¨¡å‹é…ç½®
  relation_extraction:
    enabled: true
    method: "rule_based"
    sentence_window: 2
    confidence_threshold: 0.5
    evidence_aggregation: true
    
  # è§„åˆ™é”šç‚¹è¯†åˆ«é…ç½®
  rule_anchor:
    enabled: true
    use_ac_automaton: true
    normalization: true
    conflict_resolution: "priority_based"
    priority_map:
      CellLine: 1
      Protein: 2
      Reagent: 3
      Product: 4
      Metric: 5
```

### 2) ğŸ“¥ åˆ›å»ºæ¨¡å‹ä¸‹è½½è„šæœ¬

**æ–‡ä»¶**: `install/bert-base-chinese+transformers-4.36.sh`

**åŠŸèƒ½ç‰¹æ€§**:
- âœ… æ”¯æŒé˜¿é‡Œäº‘é•œåƒæºï¼Œæé«˜ä¸‹è½½æˆåŠŸç‡
- âœ… è‡ªåŠ¨æ£€æµ‹å·²ä¸‹è½½æ¨¡å‹ï¼Œé¿å…é‡å¤ä¸‹è½½
- âœ… æä¾›è¯¦ç»†çš„ä¸‹è½½è¿›åº¦å’ŒéªŒè¯ä¿¡æ¯
- âœ… åŒ…å«å®Œæ•´çš„é…ç½®ä½¿ç”¨è¯´æ˜
- âœ… æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œé”™è¯¯é‡è¯•
- âœ… ä¸é¡¹ç›®ç°æœ‰ä¸‹è½½è„šæœ¬æ¶æ„ä¸€è‡´

**ä½¿ç”¨æ–¹å¼**:
```bash
cd install
./bert-base-chinese+transformers-4.36.sh
```

### 3) ğŸ”§ æ›´æ–°PdfGraphServiceé…ç½®åŠ è½½

**æ–‡ä»¶**: `app/service/pdf/PdfGraphService.py`

**ä¸»è¦æ”¹è¿›**:
- âœ… æ‰€æœ‰æ¨¡å‹é…ç½®ä»`config/model.yaml`è¯»å–
- âœ… æ”¯æŒenabled/disabledå¼€å…³æ§åˆ¶
- âœ… å®ç°é™çº§æœºåˆ¶ï¼ˆæ¨¡å‹åŠ è½½å¤±è´¥æ—¶è‡ªåŠ¨é™çº§åˆ°è§„åˆ™æ–¹æ³•ï¼‰
- âœ… ç»Ÿä¸€ç¼“å­˜ç›®å½•ç®¡ç†
- âœ… è¯¦ç»†çš„é”™è¯¯æ—¥å¿—å’ŒçŠ¶æ€è®°å½•

**é…ç½®åŠ è½½ç¤ºä¾‹**:
```python
# NERé…ç½®è¯»å–
kg_config = model_config.get('knowledge_graph', {})
ner_config = kg_config.get('ner', {})
self.model_name = ner_config.get('model_name', 'bert-base-chinese')
self.enabled = ner_config.get('enabled', True)
self.fallback_to_rules = ner_config.get('fallback_to_rules', True)

# æ¨¡å‹åˆå§‹åŒ–
if self.enabled:
    try:
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_name,
            cache_dir=self.cache_dir
        )
    except Exception as e:
        if self.fallback_to_rules:
            self.logger.warning(f"NERæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œé™çº§åˆ°è§„åˆ™æ–¹æ³•: {e}")
```

### 4) ğŸ“¦ æ›´æ–°ä¸‹è½½ç®¡ç†è„šæœ¬

**æ–‡ä»¶**: `install/down_all.sh`

**æ–°å¢åŠŸèƒ½**:
- âœ… çŸ¥è¯†å›¾è°±æ¨¡å‹åˆ†ç±»æ˜¾ç¤º
- âœ… è‡ªåŠ¨è¯†åˆ«æ–°çš„BERTä¸‹è½½è„šæœ¬
- âœ… ç»Ÿä¸€çš„æ¨¡å‹ç®¡ç†ç•Œé¢

**åˆ†ç±»æ˜¾ç¤º**:
```bash
ğŸ§  çŸ¥è¯†å›¾è°±æ¨¡å‹:
     - bert-base-chinese (v4.36.x)
     - bge-reranker-large (å¦‚æœå­˜åœ¨)
```

### 5) ğŸ“‹ ä¾èµ–ç®¡ç†

**æ–‡ä»¶**: `requirements.txt`

**å·²æ·»åŠ **:
```txt
pyahocorasick>=1.4.4,<2.0.0  # ACè‡ªåŠ¨æœºï¼Œç”¨äºè§„åˆ™é”šç‚¹è¯†åˆ«
```

**ç°æœ‰ç›¸å…³ä¾èµ–**:
- `transformers>=4.36.0` - BERT tokenizer
- `sentence-transformers>=2.7.0` - åµŒå…¥æ¨¡å‹
- `torch>=2.0.0` - æ·±åº¦å­¦ä¹ æ¡†æ¶

## ğŸ¤– é‡æ„åéœ€è¦çš„æ¨¡å‹æ¸…å•

### ğŸ“Š æ ¸å¿ƒæ¨¡å‹åˆ—è¡¨

| æ¨¡å‹ç±»å‹ | æ¨¡å‹åç§° | ç”¨é€” | é…ç½®ä½ç½® | ä¸‹è½½è„šæœ¬ |
|---------|---------|------|---------|---------|
| **NER Tokenizer** | `bert-base-chinese` | ç»Ÿè®¡å¼NERæ–‡æœ¬åˆ†è¯ | `knowledge_graph.ner.model_name` | `bert-base-chinese+transformers-4.36.sh` |
| **Bi-encoder** | `paraphrase-multilingual-mpnet-base-v2` | å®ä½“é“¾æ¥å¬å› | `knowledge_graph.entity_linking.bi_encoder` | `paraphrase-multilingual-mpnet-base-v2+2.7.0.sh` |
| **Cross-encoder** | `BAAI/bge-reranker-large` | å®ä½“é“¾æ¥é‡æ’ | `knowledge_graph.entity_linking.cross_encoder` | å¤ç”¨`reranker.model_name` |
| **ACè‡ªåŠ¨æœº** | `pyahocorasick` | è§„åˆ™é”šç‚¹è¯†åˆ« | `rule_anchor.use_ac_automaton` | `pip install` |

### ğŸ—ï¸ æ¨¡å‹ä½¿ç”¨æ¶æ„

```
çŸ¥è¯†å›¾è°±å»ºè®¾æµç¨‹ï¼š
â”œâ”€â”€ 1) è§„åˆ™é”šç‚¹è¯†åˆ«
â”‚   â””â”€â”€ pyahocorasick (ACè‡ªåŠ¨æœº) + è¯å…¸æ²»ç†
â”œâ”€â”€ 2) ç»Ÿè®¡å¼NER  
â”‚   â””â”€â”€ bert-base-chinese (tokenizer) + offset_mapping
â”œâ”€â”€ 3) å®ä½“é“¾æ¥(EL)
â”‚   â”œâ”€â”€ paraphrase-multilingual-mpnet-base-v2 (å¬å›)
â”‚   â””â”€â”€ BAAI/bge-reranker-large (é‡æ’)
â”œâ”€â”€ 4) å…³ç³»æŠ½å–(RE)
â”‚   â””â”€â”€ rule_based (å¯æ‰©å±•ä¸ºmodel_based)
â””â”€â”€ 5) Neo4jä¿å­˜
    â””â”€â”€ æ‰¹é‡MERGEæ“ä½œ
```

## ğŸš€ ä½¿ç”¨æŒ‡å—

### ğŸ“¥ æ¨¡å‹ä¸‹è½½

**æ–¹æ³•1: å•ç‹¬ä¸‹è½½ï¼ˆæ¨èï¼‰**
```bash
cd install
./bert-base-chinese+transformers-4.36.sh
```

**æ–¹æ³•2: æ‰¹é‡ä¸‹è½½**
```bash
cd install  
./down_all.sh
# é€‰æ‹© 0 (ä¸‹è½½æ‰€æœ‰æ¨¡å‹)
```

### ğŸ”§ é…ç½®è°ƒæ•´

åœ¨`config/model.yaml`ä¸­è°ƒæ•´çŸ¥è¯†å›¾è°±æ¨¡å‹é…ç½®ï¼š

```yaml
knowledge_graph:
  ner:
    enabled: true/false          # å¼€å¯/å…³é—­NERæ¨¡å‹
    fallback_to_rules: true      # æ¨¡å‹å¤±è´¥æ—¶é™çº§åˆ°è§„åˆ™
  entity_linking:
    enabled: true/false          # å¼€å¯/å…³é—­å®ä½“é“¾æ¥
    candidate_top_k: 10          # å¬å›å€™é€‰æ•°é‡
  relation_extraction:
    method: "rule_based"         # rule_based æˆ– model_based
```

### ğŸ” æœåŠ¡ä½¿ç”¨

é‡æ„åçš„æœåŠ¡æ¥å£ä¿æŒä¸å˜ï¼š

```python
from app.service.pdf.PdfGraphService import PdfGraphService

service = PdfGraphService()
result = service.process_pdf_json_to_graph(json_data, document_id)

# è¿”å›è¯¦ç»†ç»Ÿè®¡
{
    'success': True,
    'entities_count': 25,
    'relations_count': 12,
    'anchors_count': 15,
    'ner_entities_count': 18,
    'linked_count': 20
}
```

## ğŸ¯ æŠ€æœ¯äº®ç‚¹

### ğŸ›¡ï¸ é™çº§æœºåˆ¶
- **NERæ¨¡å‹åŠ è½½å¤±è´¥** â†’ è‡ªåŠ¨é™çº§åˆ°è§„åˆ™æ–¹æ³•
- **å®ä½“é“¾æ¥å¤±è´¥** â†’ ä¿ç•™åŸå§‹å®ä½“æ–‡æœ¬  
- **å…³ç³»æŠ½å–å¤±è´¥** â†’ è·³è¿‡å…³ç³»å»ºè®¾ï¼Œä¿ç•™å®ä½“

### ğŸ“Š é…ç½®çµæ´»æ€§
- **ç»Ÿä¸€é…ç½®ç®¡ç†**: æ‰€æœ‰æ¨¡å‹é…ç½®é›†ä¸­åœ¨`model.yaml`
- **ç»„ä»¶å¼€å…³æ§åˆ¶**: æ¯ä¸ªç»„ä»¶éƒ½å¯ç‹¬ç«‹å¯ç”¨/ç¦ç”¨
- **å‚æ•°å¯è°ƒèŠ‚**: é˜ˆå€¼ã€æ‰¹æ¬¡å¤§å°ã€è®¾å¤‡ç­‰å‚æ•°å¯é…ç½®

### ğŸ”§ å·¥ç¨‹å®ç”¨æ€§
- **å¤ç”¨ç°æœ‰åŸºç¡€è®¾æ–½**: ä½¿ç”¨é¡¹ç›®ç°æœ‰çš„ä¸‹è½½è„šæœ¬æ¶æ„
- **å…¼å®¹æ€§è‰¯å¥½**: ä¿æŒåŸæœ‰æ¥å£ä¸å˜
- **é”™è¯¯å¤„ç†å®Œå–„**: è¯¦ç»†çš„æ—¥å¿—å’Œå¼‚å¸¸å¤„ç†

## âœ… éªŒè¯ç»“æœ

å·²é€šè¿‡ä»¥ä¸‹éªŒè¯ï¼š
- âœ… é…ç½®æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œæ‰€æœ‰å¿…éœ€å­—æ®µé½å…¨
- âœ… ä¸‹è½½è„šæœ¬å¯æ‰§è¡Œï¼ŒåŒ…å«æ­£ç¡®çš„æ¨¡å‹ä¿¡æ¯
- âœ… PdfGraphServiceå¯æ­£å¸¸å¯¼å…¥å’Œåˆå§‹åŒ–é…ç½®
- âœ… æ¨¡å‹ä¾èµ–(transformers, sentence-transformersç­‰)å¯ç”¨
- âš ï¸  pyahocorasickåœ¨æŸäº›ç¯å¢ƒä¸­å¯¼å…¥æœ‰é—®é¢˜ï¼ˆå·²å®‰è£…ä½†å¯¼å…¥å¤±è´¥ï¼‰

## ğŸš© å·²çŸ¥é—®é¢˜

1. **pyahocorasickå¯¼å…¥é—®é¢˜**: åœ¨æŸäº›ç¯å¢ƒä¸­å¯èƒ½é‡åˆ°å¯¼å…¥é”™è¯¯ï¼Œä½†ä¸å½±å“ç³»ç»Ÿè¿è¡Œï¼ˆæœ‰é™çº§æœºåˆ¶ï¼‰
2. **æ¨¡å‹æ–‡ä»¶å¤§å°**: BERTæ¨¡å‹çº¦400MBï¼Œé¦–æ¬¡ä¸‹è½½éœ€è¦æ—¶é—´
3. **è®¾å¤‡é…ç½®**: é»˜è®¤ä½¿ç”¨CPUï¼Œå¦‚éœ€GPUéœ€æ‰‹åŠ¨é…ç½®

## ğŸ”„ åç»­æ‰©å±•å»ºè®®

1. **ä¸“é—¨çš„NERæ¨¡å‹**: å½“å‰ä½¿ç”¨BERT tokenizerï¼Œå¯å‡çº§ä¸ºä¸“é—¨çš„ä¸­æ–‡NERæ¨¡å‹
2. **å…³ç³»æŠ½å–æ¨¡å‹**: æ”¯æŒä»rule_basedå‡çº§ä¸ºmodel_basedï¼ˆTPLinker/GPLinkerï¼‰
3. **å¤šè¯­è¨€æ”¯æŒ**: é…ç½®ä¸åŒè¯­è¨€çš„æ¨¡å‹
4. **æ¨¡å‹ç‰ˆæœ¬ç®¡ç†**: æ”¯æŒæ¨¡å‹ç‰ˆæœ¬æ›´æ–°å’Œå›æ»š

## ğŸ‰ æ€»ç»“

âœ… **é—®é¢˜1: éœ€è¦ç”¨åˆ°æ¨¡å‹ä¹ˆï¼Ÿ**
- **ç­”**: æ˜¯çš„ï¼Œé‡æ„åéœ€è¦4ç§ç±»å‹çš„æ¨¡å‹ï¼šNER tokenizerã€Bi-encoderã€Cross-encoderã€ACè‡ªåŠ¨æœº

âœ… **é—®é¢˜2: æ¨¡å‹ä¸ºä»€ä¹ˆæ²¡æœ‰æ”¾åœ¨é…ç½®æ–‡ä»¶ä¸­ï¼Ÿ**
- **ç­”**: å·²å®Œå–„ï¼Œç°åœ¨æ‰€æœ‰æ¨¡å‹é…ç½®éƒ½åœ¨`config/model.yaml`çš„`knowledge_graph`éƒ¨åˆ†

âœ… **é—®é¢˜3: ä¸ºä»€ä¹ˆæ²¡æœ‰åˆ›å»ºä¸‹è½½è„šæœ¬ï¼Ÿ**
- **ç­”**: å·²åˆ›å»º`bert-base-chinese+transformers-4.36.sh`ä¸‹è½½è„šæœ¬ï¼Œå¹¶æ›´æ–°äº†ç»Ÿä¸€ä¸‹è½½ç®¡ç†

**é‡æ„åçš„çŸ¥è¯†å›¾è°±åŠŸèƒ½ç°å·²å…·å¤‡å®Œæ•´çš„æ¨¡å‹é…ç½®å’Œä¸‹è½½æœºåˆ¶ï¼** ğŸ‰
