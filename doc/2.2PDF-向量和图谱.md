我现在的这个项目是要做一个GraphRAG系统，总体目标是当用户输入一个问题的时候，可以分析出这个问题是标题还是内容，然后可以将和这个问题相关的所有内容展示给用户，这个内容必须是完整的，例如如果是一个标题，那么展示的内容应该是标题加上正文（文本、图表、图片、表格等），如果是正文的某个片段那么应该展示这个正文对应的标题和完整的正文内容。现在需要按照这个目标去准备数据，20240906-CHO试剂盒单页_doc_1_hi_res.json这个文件是从pdf提取出来的内容保存到了这个json文件中，从内容可以看到有标题，还有正文，但是正文已经被分成了多段，如果我要实现这个功能，如何处理这个数据才可以实现？
例如：
1.若果要向量化，那么如何处理这个json文件的数据？
2.如果要存图数据库，那么如何处理这个json文件的数据？（如果这步骤和向量化用到的数据格式一样是否只处理一次就行了）
要求：
1.严格按照上述的总体目标设计并实现向量化功能，在PdfVectorService.py这个文件中实现向量化的所有内容
2.严格按照上述的总体目标设计并实现知识图谱功能，在PdfGraphService.py这个文件中实现知识图谱的所有内容
3.向量化数据库和图数据库已经存在对应的管理器，不要重复实现
4.严格按照这个要求实现，不要扩散思路和需求


优化（向量）：
数据提取阶段产生的json数据中包含id，并且这个id已经将“一家子”关联在一起，内容都通过parent_id绑定title。向量化产生的content_units没有包含element_id，这个element_id应该用title的id，保证每个content_units都是“一家子”，同时在这个阶段需要产生这“一家子”的结构化数据，保存到mysql中，用来在召回的时候，能准确拿到图片、图表、表格等详细信息。如果要实现这个功能需要做以下调整：
1.调整向量数据库的结构，增加“element_id”，用来保存“一家子”的唯一id
2.调整content_units，增加element_id，这个element_id的值是“这家子”的title的id，增加table、img、chars标签，保留表格、图片、图表的详细信息（表格结构、图片路径等），table、img、chars这三个标签在向量化时没有用，它是为了其他功能准备的，同时保证产生的json中也要包含新加的这些内容
3.调整document_chunks的结构，增加element_id，当完成一个content_units的向量化操作后，将这个content_units保存到document_chunks表其中content就用来保存这个content_units的json数据


重构（向量）：
1.调整process_pdf_json_to_vectors函数的参数为json_data
2.重构PdfVectorService.py的向量化实现逻辑，要求：
1）根据json_data中的数据向量化，titles 用 full_text；fragments 用 blocks[*].text/row_text/caption；
2）删除这个类中一切不需要的方法和函数

优化（倒排）：
1.在步骤2之后步骤3之前增加一个步骤2.1：倒排
2.调用PdfBM25Service.py的函数，参数为json_data，实现倒排

优化（知识图谱）：
doc_1.json这个文件是提取pdf数据的文件，content_units.json这个文件是加工doc_1.json文件后用来做向量化的数据文件，现在需要构建实体关系，我不知道该用哪个数据，或者说应该基于哪个数据来加工一个构建知识图谱的数据更好。我的目标是“当用户输入一个问题的时候，可以分析出这个问题是标题还是内容，然后可以将和这个问题相关的所有内容展示给用户，这个内容必须是完整的，例如如果是一个标题，那么展示的内容应该是标题加上正文（文本、图表、图片、表格等），如果是正文的某个片段那么应该展示这个正文对应的标题和完整的正文内容”，现在向量化的环节已经实现完，详细分析下如果要实现这个功能，应该如何构建知识图谱

重构（知识图谱）：
重构步骤3的process_pdf_json_to_graph函数，入参改为json_data，并且按照这个格式重新实现图谱的构建，要求：
1.对每个 block（Paragraph/Table row/Figure caption）跑 NER/模板/LLM：
识别 实体：CHO-K1(CellLine), HCP(Protein/Analyte), 抗体(Reagent), 试剂盒(Product)…
识别 指标/数值：覆盖率 80%+、线性范围 1–100 ng/mL、R² 0.998（若在表格）
产出 Mention（锚定原文）：{elem_id, section_id, span_text, page, bbox}
规范化（别名/缩写表）：HCP ↔ 宿主蛋白、CHO-K1 归一到同一实体 ID
工程上可先用规则+词典（正则抓 %、区间、单位；词典匹配 CHO-K1/HCP），再用 LLM 做补充与消歧，效果稳定且可控。
2.入图的数据模型（推荐）
1）节点
a.Section(section_id, title, …)（已存在）
b.Paragraph/Table/Figure(elem_id, …)（已存在）
c.Entity(uid, name, type)：type∈{CellLine, Analyte, Product, Reagent, Metric, Unit}
d.（可选）Claim：承载“带数值的事实”，便于溯源与对比
2)关系
a.(:Block)-[:MENTIONS]->(:Entity)（带 span_text、page/bbox 方便高亮）
b.(:Section)-[:HAS_ENTITY]->(:Entity)（从 mentions 汇总而来，加速检索）
c.语义关系（从句式/表格抽）：
c1.(:Product)-[:MEASURES]->(:Analyte)（试剂盒→HCP）
c2.(:Product)-[:APPLICABLE_TO]->(:CellLine)（适用 CHO-K1 系统）
c3.(:Product)-[:USED_FOR]->(:Process {name:'质量控制/放行'})
c4.(:Product)-[:HAS_METRIC]->(:Metric {name:'覆盖率'})
c5.(:Metric)-[:VALUE]->(:Claim {value:0.8, unit:'%', qualifier:'2D Gel/Western'})
3)所有关系都带来源：{section_id, elem_id, sentence}，保证可追溯。
3.规范化表（同义词、缩写、单位）：MySQL 一张 entity_dictionary 表，入图前统一 UID。
去重：实体 uid 建唯一约束；关系可按 (src_uid, dst_uid, predicate, source) 去重。
可回溯：每条关系/Claim 必带 section_id/elem_id/sentence/page/bbox。
灰度：实体抽取先跑“规则+词典”，LLM 结果置为 confidence 低的候选，人工或校验通过后再转正。


优化（保存数据到mysql）：
在步骤3之后，所有步骤完成之前，增加一个步骤4，这个步骤将json_data保存到mysql，要求：
1.sections（一节一行）、figures（一图一行）、tables（一表一行）、table_rows（一行一行）。
主键用 section_id/elem_id 与 Neo4j、向量库、ES 完全一致。
2.映射规则（Manifest → MySQL）
1）sections
来自 manifest.section_id / doc_id / version / title / page_start / page_end
2）figures（遍历 blocks.type='figure'）
elem_id = block.elem_id
section_id = manifest.section_id
image_path = block.image_path
caption = block.caption
page = block.page
bbox_norm = normalize_bbox(block.bbox, page_w, page_h)
bind_to_elem_id（若清单里有图文绑定）
3）tables（遍历 blocks.type='table'）
elem_id = block.elem_id
section_id = manifest.section_id
table_html = block.html
n_rows = len(block.rows)，n_cols = 推断/解析列数
4）table_rows
对 block.rows：
table_elem_id = block.elem_id
row_index = 序号
row_text = 规范化行文本（例如：项目: 线性范围 | 数值: 1–100 ng/mL | R²: 0.998）
row_json = 行的原始键值对（如 {"项目":"线性范围","数值":"1–100 ng/mL","R2":"0.998"}）
3.在PdfMysqlService.py文件中实现上述内容

