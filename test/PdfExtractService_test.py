# -*- coding: utf-8 -*-
"""
AIæ ¸å¿ƒPDFå†…å®¹æå–æœåŠ¡æµ‹è¯•è„šæœ¬
åŸºäºç²¾ç®€åŒ–JSONç»“æ„çš„PDFæ–‡æ¡£ç»“æ„åŒ–å†…å®¹æå–æµ‹è¯•
"""

import sys
import os
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.service.pdf.PdfExtractService import extract_pdf_content


def test_ai_core_pdf_extraction():
    """æµ‹è¯•AIæ ¸å¿ƒPDFå†…å®¹æå–åŠŸèƒ½"""
    # æµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼ˆè¯·æ›¿æ¢ä¸ºå®é™…çš„PDFæ–‡ä»¶è·¯å¾„ï¼‰
    test_files = [
        "/Users/craig-mac/Downloads/å¤šå®äº§å“æ‰‹å†Œ/20240906-CHOè¯•å‰‚ç›’å•é¡µ.pdf",
        # å¯ä»¥æ·»åŠ æ›´å¤šæµ‹è¯•æ–‡ä»¶è·¯å¾„
    ]
    
    for pdf_path in test_files:
        if not os.path.exists(pdf_path):
            print(f"âš ï¸  æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {pdf_path}")
            continue
            
        print(f"\n{'='*60}")
        print(f"ğŸ” æ­£åœ¨æµ‹è¯•PDFæ–‡ä»¶: {pdf_path}")
        print(f"{'='*60}")
        
        try:
            # æ‰§è¡ŒAIæ ¸å¿ƒPDFå†…å®¹æå–
            result = extract_pdf_content(pdf_path)
            
            # éªŒè¯æ–°çš„JSONç»“æ„
            if 'document_info' not in result or 'elements' not in result:
                print(f"âŒ JSONç»“æ„é”™è¯¯: ç¼ºå°‘å¿…éœ€çš„é¡¶çº§å­—æ®µ")
                continue
            
            # æ‰“å°æ–‡æ¡£æ ¸å¿ƒä¿¡æ¯
            doc_info = result['document_info']
            print(f"ğŸ“„ æ–‡æ¡£æ ¸å¿ƒä¿¡æ¯:")
            print(f"  - æ–‡ä»¶å: {doc_info['file_name']}")
            print(f"  - æ–‡æ¡£å“ˆå¸Œ: {doc_info['file_hash'][:16]}...")
            print(f"  - æ€»é¡µæ•°: {doc_info['total_pages']}")
            
            # åˆ†æAIæ ¸å¿ƒå…ƒç´ 
            elements = result['elements']
            print(f"\nğŸ¯ AIæ ¸å¿ƒå…ƒç´ åˆ†æ:")
            print(f"  - æœ‰æ•ˆå…ƒç´ æ•°: {len(elements)}")
            
            # ç»Ÿè®¡å„å­—æ®µå®Œæ•´æ€§
            vectorization_count = sum(1 for elem in elements if elem.get('vectorization_text'))
            coordinates_count = sum(1 for elem in elements if elem.get('coordinates'))
            context_count = sum(1 for elem in elements if elem.get('context_info'))
            
            print(f"  - å¯å‘é‡åŒ–å…ƒç´ : {vectorization_count}/{len(elements)} ({vectorization_count/len(elements)*100:.1f}%)")
            print(f"  - åŒ…å«åæ ‡å…ƒç´ : {coordinates_count}/{len(elements)} ({coordinates_count/len(elements)*100:.1f}%)")
            print(f"  - åŒ…å«ä¸Šä¸‹æ–‡å…ƒç´ : {context_count}/{len(elements)} ({context_count/len(elements)*100:.1f}%)")
            
            # åˆ†æé¡µé¢åˆ†å¸ƒ
            page_distribution = {}
            for elem in elements:
                page = elem.get('page_number')
                if page is None:
                    page = 'Unknown'
                page_distribution[page] = page_distribution.get(page, 0) + 1
            
            print(f"\nğŸ“Š é¡µé¢åˆ†å¸ƒ:")
            # å°†Unknownæ”¾åˆ°æœ€åï¼Œæ•°å­—é¡µé¢æŒ‰é¡ºåºæ’åˆ—
            sorted_pages = []
            unknown_count = 0
            for page, count in page_distribution.items():
                if page == 'Unknown':
                    unknown_count = count
                else:
                    sorted_pages.append((page, count))
            
            # æŒ‰é¡µç æ’åº
            sorted_pages.sort(key=lambda x: x[0])
            
            for page, count in sorted_pages:
                print(f"  - ç¬¬{page}é¡µ: {count}ä¸ªå…ƒç´ ")
            if unknown_count > 0:
                print(f"  - æœªçŸ¥é¡µé¢: {unknown_count}ä¸ªå…ƒç´ ")
            
            # åˆ†æå…ƒç´ ç±»å‹ï¼ˆé€šè¿‡context_infoï¼‰
            type_distribution = {}
            for elem in elements:
                context = elem.get('context_info', {})
                elem_type = context.get('type_context', {}).get('element_type', 'Unknown')
                type_distribution[elem_type] = type_distribution.get(elem_type, 0) + 1
            
            print(f"\nğŸ·ï¸  å…ƒç´ ç±»å‹åˆ†å¸ƒ:")
            for elem_type, count in type_distribution.items():
                print(f"  - {elem_type}: {count}ä¸ª")
            
            # å±•ç¤ºAIæ ¸å¿ƒå…ƒç´ ç¤ºä¾‹
            print(f"\nğŸ¯ AIæ ¸å¿ƒå…ƒç´ ç¤ºä¾‹:")
            for i, element in enumerate(elements[:3], 1):
                print(f"  å…ƒç´ {i}:")
                print(f"    - ID: {element['element_id']}")
                print(f"    - é¡µç : {element.get('page_number', 'N/A')}")
                print(f"    - å‘é‡åŒ–æ–‡æœ¬: {element['vectorization_text'][:60]}...")
                print(f"    - åŸå§‹æ–‡æœ¬: {element['text_content'][:40]}...")
                
                # æ˜¾ç¤ºä¸Šä¸‹æ–‡ä¿¡æ¯
                context = element.get('context_info', {})
                if context:
                    pos_info = context.get('position_in_document', {})
                    type_info = context.get('type_context', {})
                    print(f"    - æ–‡æ¡£ä½ç½®: ç´¢å¼•{pos_info.get('index', 'N/A')}, ç›¸å¯¹ä½ç½®{pos_info.get('relative_position', 0):.2f}")
                    print(f"    - å…ƒç´ ç±»å‹: {type_info.get('element_type', 'N/A')}")
                print()
            
            # æ£€æŸ¥æ˜¯å¦è‡ªåŠ¨ä¿å­˜äº†JSON
            if result.get('saved_json_path'):
                saved_path = result['saved_json_path']
                try:
                    file_size = os.path.getsize(saved_path)
                    print(f"ğŸ’¾ è‡ªåŠ¨ä¿å­˜ä¿¡æ¯:")
                    print(f"  - ä¿å­˜è·¯å¾„: {saved_path}")
                    print(f"  - æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚")
                except:
                    print(f"ğŸ’¾ æ–‡ä»¶å·²è‡ªåŠ¨ä¿å­˜åˆ°: {saved_path}")
            else:
                # æ‰‹åŠ¨ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆå…¼å®¹æ—§æ–¹å¼ï¼‰
                output_file = f"{pdf_path}_ai_core_extracted.json"
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ æ‰‹åŠ¨ä¿å­˜ç»“æœåˆ°: {output_file}")
            
            print(f"\nâœ… AIæ ¸å¿ƒPDFæå–æˆåŠŸ!")
            print(f"ğŸ‰ JSONç»“æ„éªŒè¯é€šè¿‡ï¼Œç¬¦åˆAIæ ¸å¿ƒåŠŸèƒ½è¦æ±‚!")
            
        except Exception as e:
            print(f"âŒ PDFæå–å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()


def create_sample_test_structure():
    """åˆ›å»ºç¤ºä¾‹æµ‹è¯•ç»“æ„"""
    upload_dir = Path(project_root) / "upload" / "pdf"
    upload_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"å·²åˆ›å»ºä¸Šä¼ ç›®å½•: {upload_dir}")
    print(f"è¯·å°†æµ‹è¯•PDFæ–‡ä»¶æ”¾å…¥æ­¤ç›®å½•ï¼Œç„¶åè¿è¡Œæµ‹è¯•")


if __name__ == "__main__":
    print("ğŸ¯ AIæ ¸å¿ƒPDFå†…å®¹æå–æœåŠ¡æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•ç›®å½•ç»“æ„
    create_sample_test_structure()
    
    # è¿è¡ŒAIæ ¸å¿ƒæå–æµ‹è¯•
    test_ai_core_pdf_extraction()
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")