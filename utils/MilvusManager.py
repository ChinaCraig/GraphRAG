"""
Milvuså‘é‡æ•°æ®åº“ç®¡ç†å™¨
è´Ÿè´£å‘é‡æ•°æ®çš„å­˜å‚¨ã€æ£€ç´¢å’Œç®¡ç†
"""

import yaml
import logging
import numpy as np
from typing import Optional, Dict, Any, List, Union
from pymilvus import (
    connections, Collection, DataType, FieldSchema, CollectionSchema,
    utility, Index, db
)
from pymilvus.exceptions import MilvusException
import json

class MilvusManager:
    """Milvuså‘é‡æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = 'config/db.yaml'):
        """
        åˆå§‹åŒ–Milvusç®¡ç†å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.collection = None
        self.logger = logging.getLogger(__name__)
        
        # åŠ è½½é…ç½®
        self._load_config()
        
        # åˆå§‹åŒ–è¿æ¥
        self._init_connection()
        
        # åˆå§‹åŒ–é›†åˆ
        self._init_collection()
    
    def _load_config(self) -> None:
        """åŠ è½½Milvusé…ç½®"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as file:
                config = yaml.safe_load(file)
                self.milvus_config = config['milvus']
                self.logger.info("Milvusé…ç½®åŠ è½½æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"åŠ è½½Milvusé…ç½®å¤±è´¥: {str(e)}")
            raise
    
    def _init_connection(self) -> None:
        """åˆå§‹åŒ–Milvusè¿æ¥"""
        try:
            # è¿æ¥åˆ°MilvusæœåŠ¡å™¨ï¼ˆä¸æŒ‡å®šæ•°æ®åº“ï¼Œå…ˆè¿æ¥åæ£€æŸ¥æ•°æ®åº“ï¼‰
            connections.connect(
                alias="default",
                host=self.milvus_config['host'],
                port=str(self.milvus_config['port']),
                timeout=self.milvus_config.get('timeout', 30)
            )
            
            self.logger.info(f"Milvusè¿æ¥æˆåŠŸ: {self.milvus_config['host']}:{self.milvus_config['port']}")
            
            # æ£€æŸ¥å¹¶åˆ›å»ºæ•°æ®åº“
            self._check_and_create_database()
            
        except MilvusException as e:
            self.logger.error(f"Milvusè¿æ¥å¤±è´¥: {str(e)}")
            raise
    
    def _check_and_create_database(self) -> None:
        """æ£€æŸ¥å¹¶åˆ›å»ºæ•°æ®åº“"""
        try:
            database_name = self.milvus_config.get('database', 'default')
            
            # è·å–æ‰€æœ‰æ•°æ®åº“åˆ—è¡¨
            databases = db.list_database()
            self.logger.info(f"ç°æœ‰æ•°æ®åº“åˆ—è¡¨: {databases}")
            
            # æ£€æŸ¥ç›®æ ‡æ•°æ®åº“æ˜¯å¦å­˜åœ¨
            if database_name not in databases:
                self.logger.info(f"æ•°æ®åº“ '{database_name}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
                db.create_database(database_name)
                self.logger.info(f"æ•°æ®åº“ '{database_name}' åˆ›å»ºæˆåŠŸ")
            else:
                self.logger.info(f"æ•°æ®åº“ '{database_name}' å·²å­˜åœ¨")
            
            # é‡æ–°è¿æ¥åˆ°æŒ‡å®šæ•°æ®åº“
            connections.disconnect(alias="default")
            connections.connect(
                alias="default",
                host=self.milvus_config['host'],
                port=str(self.milvus_config['port']),
                db_name=database_name,
                timeout=self.milvus_config.get('timeout', 30)
            )
            
            self.logger.info(f"å·²è¿æ¥åˆ°æ•°æ®åº“: {database_name}")
            
        except MilvusException as e:
            self.logger.error(f"æ•°æ®åº“æ£€æŸ¥å’Œåˆ›å»ºå¤±è´¥: {str(e)}")
            raise
    
    def _init_collection(self) -> None:
        """åˆå§‹åŒ–é›†åˆ"""
        try:
            collection_name = self.milvus_config['collection']
            
            # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
            if utility.has_collection(collection_name):
                self.collection = Collection(collection_name)
                self.logger.info(f"æ‰¾åˆ°å·²å­˜åœ¨çš„é›†åˆ: {collection_name}")
                
                # æ£€æŸ¥é›†åˆschemaæ˜¯å¦åŒ¹é…å½“å‰è¦æ±‚
                if self._check_collection_schema():
                    self.logger.info("é›†åˆschemaåŒ¹é…ï¼Œç›´æ¥ä½¿ç”¨")
                    # åŠ è½½é›†åˆåˆ°å†…å­˜
                    self.collection.load()
                    self.logger.info("é›†åˆå·²åŠ è½½åˆ°å†…å­˜")
                else:
                    self.logger.warning("é›†åˆschemaä¸åŒ¹é…ï¼Œéœ€è¦é‡æ–°åˆ›å»ºé›†åˆ")
                    # åˆ é™¤æ—§é›†åˆå¹¶åˆ›å»ºæ–°é›†åˆ
                    self._recreate_collection()
            else:
                self.logger.info(f"é›†åˆ '{collection_name}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
                # åˆ›å»ºé›†åˆ
                self._create_collection()
                
        except MilvusException as e:
            self.logger.error(f"åˆå§‹åŒ–é›†åˆå¤±è´¥: {str(e)}")
            raise
    
    def _create_collection(self) -> None:
        """åˆ›å»ºé›†åˆ"""
        try:
            collection_name = self.milvus_config['collection']
            dimension = self.milvus_config['dimension']
            
            # å®šä¹‰å­—æ®µæ¨¡å¼
            fields = [
                FieldSchema(
                    name="id",
                    dtype=DataType.VARCHAR,
                    max_length=100,
                    is_primary=True,
                    description="å”¯ä¸€æ ‡è¯†ç¬¦"
                ),
                FieldSchema(
                    name="vector",
                    dtype=DataType.FLOAT_VECTOR,
                    dim=dimension,
                    description="å‘é‡æ•°æ®"
                ),
                FieldSchema(
                    name="document_id",
                    dtype=DataType.INT64,
                    description="æ–‡æ¡£ID"
                ),
                FieldSchema(
                    name="element_id",
                    dtype=DataType.VARCHAR,
                    max_length=100,  # ğŸ”§ å¢åŠ åˆ°100å­—ç¬¦ä»¥æ”¯æŒé•¿çš„section_id
                    description="ä¸€å®¶å­çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆæ ‡é¢˜IDï¼‰"
                ),
                FieldSchema(
                    name="chunk_index",
                    dtype=DataType.INT64,
                    description="åˆ†å—ç´¢å¼•"
                ),
                FieldSchema(
                    name="content",
                    dtype=DataType.VARCHAR,
                    max_length=65535,
                    description="æ–‡æœ¬å†…å®¹"
                ),
                # ğŸ”§ æ–°å¢ï¼šç‹¬ç«‹çš„content_typeå­—æ®µï¼Œç”¨äºé«˜æ•ˆæ„å›¾åˆ¤åˆ«
                FieldSchema(
                    name="content_type",
                    dtype=DataType.VARCHAR,
                    max_length=20,
                    description="å†…å®¹ç±»å‹ï¼štitle/fragment/section/table/image"
                ),
                FieldSchema(
                    name="metadata",
                    dtype=DataType.VARCHAR,
                    max_length=65535,
                    description="å…ƒæ•°æ®"
                )
            ]
            
            # åˆ›å»ºé›†åˆæ¨¡å¼
            schema = CollectionSchema(
                fields=fields,
                description="GraphRAGå‘é‡é›†åˆ"
            )
            
            # åˆ›å»ºé›†åˆ
            self.collection = Collection(
                name=collection_name,
                schema=schema
            )
            
            # åˆ›å»ºç´¢å¼•
            self._create_index()
            
            # åŠ è½½é›†åˆåˆ°å†…å­˜
            self.collection.load()
            
            self.logger.info(f"é›†åˆåˆ›å»ºå¹¶åŠ è½½æˆåŠŸ: {collection_name}")
            
        except MilvusException as e:
            self.logger.error(f"åˆ›å»ºé›†åˆå¤±è´¥: {str(e)}")
            raise
    
    def _create_index(self) -> None:
        """åˆ›å»ºå‘é‡ç´¢å¼•"""
        try:
            index_params = {
                "index_type": self.milvus_config.get('index_type', 'IVF_FLAT'),
                "metric_type": self.milvus_config.get('metric_type', 'COSINE'),
                "params": {
                    "nlist": self.milvus_config.get('nlist', 1024)
                }
            }
            
            self.collection.create_index(
                field_name="vector",
                index_params=index_params
            )
            
            self.logger.info("å‘é‡ç´¢å¼•åˆ›å»ºæˆåŠŸ")
            
        except MilvusException as e:
            self.logger.error(f"åˆ›å»ºå‘é‡ç´¢å¼•å¤±è´¥: {str(e)}")
            raise
    
    def _check_collection_schema(self) -> bool:
        """
        æ£€æŸ¥é›†åˆschemaæ˜¯å¦åŒ¹é…å½“å‰è¦æ±‚
        ä¸»è¦æ£€æŸ¥å­—æ®µæ˜¯å¦å®Œæ•´ï¼Œç‰¹åˆ«æ˜¯æ–°æ·»åŠ çš„content_typeå­—æ®µ
        
        Returns:
            bool: Trueè¡¨ç¤ºschemaåŒ¹é…ï¼ŒFalseè¡¨ç¤ºä¸åŒ¹é…
        """
        try:
            if not self.collection:
                return False
            
            # è·å–å½“å‰é›†åˆçš„schema
            current_schema = self.collection.schema
            current_fields = {field.name: field for field in current_schema.fields}
            
            # å®šä¹‰æœŸæœ›çš„å­—æ®µåˆ—è¡¨
            expected_fields = [
                "id", "vector", "document_id", "element_id", 
                "chunk_index", "content", "content_type", "metadata"  # ğŸ”§ æ–°å¢content_typeå­—æ®µ
            ]
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰€æœ‰æœŸæœ›çš„å­—æ®µ
            missing_fields = []
            for field_name in expected_fields:
                if field_name not in current_fields:
                    missing_fields.append(field_name)
            
            if missing_fields:
                self.logger.warning(f"é›†åˆç¼ºå°‘å­—æ®µ: {missing_fields}")
                return False
            
            # ç‰¹åˆ«æ£€æŸ¥element_idå­—æ®µï¼ˆğŸ”§ ä¿®å¤ï¼šæ›´æ–°æœŸæœ›é•¿åº¦ä¸º100ï¼‰
            if "element_id" in current_fields:
                element_id_field = current_fields["element_id"]
                if (element_id_field.dtype != DataType.VARCHAR or 
                    element_id_field.params.get("max_length", 0) != 100):
                    self.logger.warning("element_idå­—æ®µç±»å‹æˆ–é•¿åº¦ä¸åŒ¹é…")
                    return False
            
            self.logger.info("é›†åˆschemaæ£€æŸ¥é€šè¿‡")
            return True
            
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥é›†åˆschemaå¤±è´¥: {str(e)}")
            return False
    
    def _recreate_collection(self) -> None:
        """é‡æ–°åˆ›å»ºé›†åˆï¼ˆåˆ é™¤æ—§é›†åˆååˆ›å»ºæ–°é›†åˆï¼‰"""
        try:
            collection_name = self.milvus_config['collection']
            
            self.logger.info(f"å¼€å§‹é‡æ–°åˆ›å»ºé›†åˆ: {collection_name}")
            
            # é‡Šæ”¾å¹¶åˆ é™¤æ—§é›†åˆ
            if self.collection:
                self.collection.release()
                utility.drop_collection(collection_name)
                self.logger.info("æ—§é›†åˆå·²åˆ é™¤")
            
            # åˆ›å»ºæ–°é›†åˆ
            self._create_collection()
            self.logger.info("é›†åˆé‡æ–°åˆ›å»ºå®Œæˆ")
            
        except MilvusException as e:
            self.logger.error(f"é‡æ–°åˆ›å»ºé›†åˆå¤±è´¥: {str(e)}")
            raise
    
    def insert_vectors(self, data: List[Dict[str, Any]]) -> bool:
        """
        æ’å…¥å‘é‡æ•°æ®
        
        Args:
            data: å‘é‡æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«id, vector, document_id, element_id, chunk_index, content, content_type, metadata
            
        Returns:
            bool: æ’å…¥æˆåŠŸè¿”å›True
        """
        try:
            if not data:
                self.logger.warning("æ²¡æœ‰æ•°æ®éœ€è¦æ’å…¥")
                return True
            
            # å‡†å¤‡æ’å…¥æ•°æ®
            ids = []
            vectors = []
            document_ids = []
            element_ids = []
            chunk_indices = []
            contents = []
            content_types = []  # ğŸ”§ æ–°å¢ï¼šcontent_typeå­—æ®µ
            metadatas = []
            
            for i, item in enumerate(data):
                # è°ƒè¯•ï¼šæ£€æŸ¥æ¯ä¸ªå­—æ®µçš„ç±»å‹
                item_id = item["id"]
                if not isinstance(item_id, str):
                    self.logger.error(f"æ•°æ®é¡¹ {i}: id ä¸æ˜¯å­—ç¬¦ä¸²ç±»å‹: {type(item_id)}, å€¼: {item_id}")
                    raise ValueError(f"idå­—æ®µå¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼Œä½†æ”¶åˆ°: {type(item_id)}")
                
                ids.append(item_id)
                vectors.append(item["vector"])
                document_ids.append(item["document_id"])
                element_ids.append(item["element_id"])
                chunk_indices.append(item["chunk_index"])
                contents.append(item["content"])
                # ğŸ”§ å¤„ç†content_typeå­—æ®µï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä»metadataä¸­æå–
                content_type = item.get("content_type")
                if not content_type:
                    # å‘åå…¼å®¹ï¼šä»metadataä¸­æå–
                    metadata = item.get("metadata", {})
                    if isinstance(metadata, dict):
                        content_type = metadata.get("content_type", "fragment")
                    else:
                        # å¦‚æœmetadataæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
                        try:
                            metadata_dict = json.loads(metadata)
                            content_type = metadata_dict.get("content_type", "fragment")
                        except:
                            content_type = "fragment"
                content_types.append(content_type)
                metadatas.append(json.dumps(item.get("metadata", {}), ensure_ascii=False))
            
            # ä½¿ç”¨å®ä½“åˆ—è¡¨æ–¹å¼æ’å…¥ï¼ˆå…¼å®¹æ€§æ›´å¥½ï¼‰
            entities = [
                ids,           # idå­—æ®µ
                vectors,       # vectorå­—æ®µ
                document_ids,  # document_idå­—æ®µ
                element_ids,   # element_idå­—æ®µ
                chunk_indices, # chunk_indexå­—æ®µ
                contents,      # contentå­—æ®µ
                content_types, # ğŸ”§ æ–°å¢ï¼šcontent_typeå­—æ®µ
                metadatas      # metadataå­—æ®µ
            ]
            
            # è°ƒè¯•ï¼šéªŒè¯entitiesç»“æ„
            self.logger.debug(f"entitiesé•¿åº¦: {len(entities)} (åº”è¯¥æ˜¯8ä¸ªå­—æ®µ)")
            self.logger.debug(f"idåˆ—è¡¨é•¿åº¦: {len(entities[0])}")
            self.logger.debug(f"å‰3ä¸ªid: {entities[0][:3]}")
            self.logger.debug(f"å‰3ä¸ªcontent_type: {entities[6][:3]}")
            
            # æ’å…¥æ•°æ®
            self.collection.insert(entities)
            
            # åˆ·æ–°æ•°æ®ï¼Œç¡®ä¿æ•°æ®è¢«æŒä¹…åŒ–
            self.collection.flush()
            
            self.logger.info(f"å‘é‡æ•°æ®æ’å…¥æˆåŠŸï¼Œå…±æ’å…¥{len(data)}æ¡è®°å½•")
            return True
            
        except MilvusException as e:
            self.logger.error(f"æ’å…¥å‘é‡æ•°æ®å¤±è´¥: {str(e)}")
            return False
    
    def search_vectors(self, query_vectors: List[List[float]], top_k: int = 10, 
                      search_params: Optional[Dict] = None, 
                      expr: Optional[str] = None) -> List[Dict]:
        """
        å‘é‡ç›¸ä¼¼æ€§æœç´¢
        
        Args:
            query_vectors: æŸ¥è¯¢å‘é‡åˆ—è¡¨
            top_k: è¿”å›çš„ç›¸ä¼¼å‘é‡æ•°é‡
            search_params: æœç´¢å‚æ•°
            expr: è¿‡æ»¤è¡¨è¾¾å¼
            
        Returns:
            List[Dict]: æœç´¢ç»“æœ
        """
        try:
            # åŠ è½½é›†åˆåˆ°å†…å­˜
            self.collection.load()
            
            # é»˜è®¤æœç´¢å‚æ•°
            if search_params is None:
                search_params = {
                    "metric_type": self.milvus_config.get('metric_type', 'COSINE'),
                    "params": {"nprobe": 16}
                }
            
            # æ‰§è¡Œæœç´¢
            results = self.collection.search(
                data=query_vectors,
                anns_field="vector",
                param=search_params,
                limit=top_k,
                expr=expr,
                output_fields=["id", "document_id", "element_id", "chunk_index", "content", "metadata"]
            )
            
            # å¤„ç†æœç´¢ç»“æœ
            search_results = []
            for hits in results:
                for hit in hits:
                    result = {
                        "id": hit.entity.get("id"),
                        "score": hit.score,
                        "document_id": hit.entity.get("document_id"),
                        "element_id": hit.entity.get("element_id"),
                        "chunk_index": hit.entity.get("chunk_index"),
                        "content": hit.entity.get("content"),
                        "metadata": json.loads(hit.entity.get("metadata", "{}"))
                    }
                    search_results.append(result)
            
            self.logger.info(f"å‘é‡æœç´¢å®Œæˆï¼Œè¿”å›{len(search_results)}æ¡ç»“æœ")
            return search_results
            
        except MilvusException as e:
            self.logger.error(f"å‘é‡æœç´¢å¤±è´¥: {str(e)}")
            return []
    
    def delete_vectors(self, expr: str) -> bool:
        """
        åˆ é™¤å‘é‡æ•°æ®
        
        Args:
            expr: åˆ é™¤æ¡ä»¶è¡¨è¾¾å¼
            
        Returns:
            bool: åˆ é™¤æˆåŠŸè¿”å›True
        """
        try:
            self.collection.delete(expr)
            self.collection.flush()
            
            self.logger.info(f"å‘é‡æ•°æ®åˆ é™¤æˆåŠŸï¼Œæ¡ä»¶: {expr}")
            return True
            
        except MilvusException as e:
            self.logger.error(f"åˆ é™¤å‘é‡æ•°æ®å¤±è´¥: {str(e)}")
            return False
    
    def delete_by_document_id(self, document_id: int) -> bool:
        """
        æŒ‰æ–‡æ¡£IDåˆ é™¤æ‰€æœ‰ç›¸å…³å‘é‡æ•°æ®
        
        Args:
            document_id: æ–‡æ¡£ID
            
        Returns:
            bool: åˆ é™¤æˆåŠŸè¿”å›True
        """
        try:
            # å…ˆæŸ¥è¯¢æœ‰å¤šå°‘æ¡è®°å½•
            count_expr = f"document_id == {document_id}"
            
            # æ‰§è¡Œåˆ é™¤
            self.collection.delete(count_expr)
            self.collection.flush()
            
            self.logger.info(f"æ–‡æ¡£ID {document_id} çš„æ‰€æœ‰å‘é‡æ•°æ®åˆ é™¤æˆåŠŸ")
            return True
            
        except MilvusException as e:
            self.logger.error(f"åˆ é™¤æ–‡æ¡£ID {document_id} çš„å‘é‡æ•°æ®å¤±è´¥: {str(e)}")
            return False
        except Exception as e:
            self.logger.error(f"åˆ é™¤æ–‡æ¡£å‘é‡æ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
            return False
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """
        è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: é›†åˆç»Ÿè®¡ä¿¡æ¯
        """
        try:
            stats = self.collection.num_entities
            return {
                "collection_name": self.collection.name,
                "total_entities": stats,
                "schema": self.collection.schema
            }
            
        except MilvusException as e:
            self.logger.error(f"è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {}
    
    def create_partition(self, partition_name: str) -> bool:
        """
        åˆ›å»ºåˆ†åŒº
        
        Args:
            partition_name: åˆ†åŒºåç§°
            
        Returns:
            bool: åˆ›å»ºæˆåŠŸè¿”å›True
        """
        try:
            if self.collection.has_partition(partition_name):
                self.logger.info(f"åˆ†åŒºå·²å­˜åœ¨: {partition_name}")
                return True
            
            self.collection.create_partition(partition_name)
            self.logger.info(f"åˆ†åŒºåˆ›å»ºæˆåŠŸ: {partition_name}")
            return True
            
        except MilvusException as e:
            self.logger.error(f"åˆ›å»ºåˆ†åŒºå¤±è´¥: {str(e)}")
            return False
    
    def query_by_id(self, ids: List[str]) -> List[Dict]:
        """
        æ ¹æ®IDæŸ¥è¯¢å‘é‡æ•°æ®
        
        Args:
            ids: IDåˆ—è¡¨
            
        Returns:
            List[Dict]: æŸ¥è¯¢ç»“æœ
        """
        try:
            self.collection.load()
            
            expr = f"id in {ids}"
            results = self.collection.query(
                expr=expr,
                output_fields=["id", "document_id", "element_id", "chunk_index", "content", "metadata"]
            )
            
            query_results = []
            for result in results:
                query_result = {
                    "id": result.get("id"),
                    "document_id": result.get("document_id"),
                    "element_id": result.get("element_id"),
                    "chunk_index": result.get("chunk_index"),
                    "content": result.get("content"),
                    "metadata": json.loads(result.get("metadata", "{}"))
                }
                query_results.append(query_result)
            
            self.logger.info(f"IDæŸ¥è¯¢å®Œæˆï¼Œè¿”å›{len(query_results)}æ¡ç»“æœ")
            return query_results
            
        except MilvusException as e:
            self.logger.error(f"IDæŸ¥è¯¢å¤±è´¥: {str(e)}")
            return []
    
    def update_vector(self, vector_id: str, new_data: Dict[str, Any]) -> bool:
        """
        æ›´æ–°å‘é‡æ•°æ®ï¼ˆé€šè¿‡åˆ é™¤åé‡æ–°æ’å…¥å®ç°ï¼‰
        
        Args:
            vector_id: å‘é‡ID
            new_data: æ–°æ•°æ®
            
        Returns:
            bool: æ›´æ–°æˆåŠŸè¿”å›True
        """
        try:
            # åˆ é™¤æ—§æ•°æ®
            self.delete_vectors(f"id == '{vector_id}'")
            
            # æ’å…¥æ–°æ•°æ®
            self.insert_vectors([new_data])
            
            self.logger.info(f"å‘é‡æ•°æ®æ›´æ–°æˆåŠŸï¼ŒID: {vector_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°å‘é‡æ•°æ®å¤±è´¥: {str(e)}")
            return False
    
    def close(self) -> None:
        """å…³é—­è¿æ¥"""
        try:
            if self.collection:
                self.collection.release()
            connections.disconnect(alias="default")
            self.logger.info("Milvusè¿æ¥å·²å…³é—­")
        except Exception as e:
            self.logger.error(f"å…³é—­Milvusè¿æ¥å¤±è´¥: {str(e)}")
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.close()